# JAVA

##  1. Static和Final的区别？

static
static是静态的意思，也是全局的意思。static定义的东西，属于全局，与类相关，不与具体实例相关，是类实例之间共享的。

1. 被static修饰的变量属于类变量，可以通过类名.变量名直接引用，而不需要new出一个对象来

2. 被static修饰的方法属于类方法，可以通过类名.方法名直接引用，而不需要new出一个对象来

static与非static的区别：

在内存中存放的位置不同：所有static修饰的属性和方法都放在内存的方法区（内存的方法区相当于常驻内存，如果一个方法或者变量声明为static，可以节约内存，不必要为每个对象实例化的时候分配内存）里，而非静态的都堆放在堆内存中

生命周期不同：静态在类消失后被销毁，非静态在对象销毁后销毁。

final
final关键字有三个东西可以修饰，修饰非抽象类，修饰非抽象方法，修饰引用。

在类的声明中使用final:

使用了final的类不能再派生子类，就是不可以被继承，简称为断子绝孙类。类中的所有方法都不能被重写。有一些java的面试题问，String可不可以被继承，答案是不可以。因为java.lang.String是一个final类。这可以保证String对象方法的调用确实运行的是String类的方法，而不是经其子类重写后的方法。

在方法的声明中使用final:

被定义为final的方法不能被重写，这个方法成为最终方法，但是该方法仍然可以被继承。如果定义类为final，是所有的方法都不能被重写。而我们只需要类中的几个方法不可以被重写，就在方法前面加上final，而且被定义为final的方法执行效率高。final不能修饰构造方法。

在修饰引用中使用final：

如果引用为基本数据类型，这样变量就是常量了，在程序中这样的变量不可以被修改，修改编译器会报错，而且执行效率比普通的变量要高。final的变量如果没有赋予初值的话，其他方法就必须给他赋值，但只能赋值一次。

如果引用为引用数据类型，比如对象，数组，则该对象、数组本身可以修改，但是指向该对象或数组的地址的引用不能修改。

如果引用的是类的成员变量，则必须当场赋值，否则编译会报错。

static和final一起用：final与static final的区别是：final在 一个对象类唯一，static final在多个对象中都唯一；一个既是static又是final的域只占据一段不能改变的存储空间，只有一份。

## 2. 为什么调用 start() 方法时会执行 run() 方法，而不能直接调用 run() 方法？

new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

总结： 调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。

## 3.sleep() 方法和 wait() 方法区别和共同点?
两者最主要的区别在于：sleep() 方法没有释放锁，而 wait() 方法释放了锁 。

两者都可以暂停线程的执行。

wait() 通常被用于线程间交互/通信，sleep()通常被用于暂停执行。

wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。sleep()方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。

# 大数据组件

## 一、 性能调优

### 1.1 如何提高Hadoop、Hive及Spark的并行度？

**Hadoop**：Hadoop的并行度取决于MapTask和ReduceTask的数量，而MapTask的数量取决于File的切片Split数量。而Split的逻辑及实现方法由FileInputFormat实现类的getSplits()方法完成。切片大小的参数取决于`mapreduce.input.fileinputformat.split.minsize`和` mapreduce.input.fileinputformat.split.maxsize` 

**Spark**：一个Spark作业是一个Application，而Application会因为行动算子而被划分为多个Jobs，一个Jobs被划分为多个task，task的数量代表了spark作业在各个阶段的并行度。至少将task的数量设置成与Spark Application的总cpu core数量相同，官方推荐设置成Application总cpu core数量的2~3倍，比如150个cpu core，设置task数量为300～500，这样的话一个task运行完以后另外的task会补过来，cpu core就不会空闲了。

提高并行度方法：

1. 调整分区数量参数`spark.default.parallelism`，该参数默认是没有值的，设置后在shuffle的过程起作用；
2. 如果读取的数据在HDFS上，可以增加block数量，默认情况下split跟block是一对一的，而split与block数量一对一，split与RDD中的partition对应，增加block数量也就增加了并行度；
3. RDD.repartition，给RDD重新设置partition的数量
4. reduceByKey算子重新指定partition的数量

5. spark.sql.shuffle.partitions sql中shuffle过程partitions的数量

**Hive**：

Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。

通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。

set hive.exec.parallel=true;              //打开任务并行执行
set hive.exec.parallel.thread.number=16;  //同一个sql允许最大并行度，默认为8。

### 1.2 Spark数据倾斜怎么解决？

**数据倾斜的原理很简单**：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。

因此出现数据倾斜的时候，Spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。

下图就是一个很清晰的例子：hello这个key，在三个节点上对应了总共7条数据，这些数据都会被拉取到同一个task中进行处理；而world和you这两个key分别才对应1条数据，所以另外两个task只要分别处理1条数据即可。此时第一个task的运行时间可能是另外两个task的7倍，而整个stage的运行速度也由运行最慢的那个task所决定。

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241613258.png" alt="img" style="zoom:80%;" />

- **解决方案一**：使用 Hive ETL预处理数据
- **解决方案二**：过滤少数导致倾斜的key
- **解决方案三**：提高shuffle操作的并行度
- **解决方案四**：两阶段聚合（局部聚合+全局聚合）
- **解决方案五**：将reduce join转为map join
- **解决方案六**：采样倾斜key并分拆join操作
- **解决方案七**：使用随机前缀和扩容RDD进行join
- **解决方案八**：多种方案组合使用

**方案适用场景**：导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。

**方案实现思路**：此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。

**方案实现原理**：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。

**方案优点**：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。

**方案缺点**：治标不治本，Hive ETL中还是会发生数据倾斜。

**方案实践经验**：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。

**项目实践经验**：在美团·点评的交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。

- 解决方案二：过滤少数导致倾斜的key

**方案适用场景**：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。

**方案实现思路**：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。

**方案实现原理**：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。

**方案优点**：实现简单，而且效果也很好，可以完全规避掉数据倾斜。

**方案缺点**：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。

**方案实践经验**：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。

- 解决方案三：提高shuffle操作的并行度

**方案适用场景**：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。

**方案实现思路**：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。

**方案实现原理**：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。

**方案优点**：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。

**方案缺点**：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。

**方案实践经验**：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。

- 解决方案四：两阶段聚合（局部聚合+全局聚合）

**方案适用场景**：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。

**方案实现思路**：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。

**方案实现原理**：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。

**方案优点**：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。

**方案缺点**：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。

![img](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241623936.png)

```java
// 第一步，给RDD中的每个key都打上一个随机前缀。
JavaPairRDD<String, Long> randomPrefixRdd = rdd.mapToPair(
        new PairFunction<Tuple2<Long,Long>, String, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, Long> call(Tuple2<Long, Long> tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(10);
                return new Tuple2<String, Long>(prefix + "_" + tuple._1, tuple._2);
            }
        });
 
// 第二步，对打上随机前缀的key进行局部聚合。
JavaPairRDD<String, Long> localAggrRdd = randomPrefixRdd.reduceByKey(
        new Function2<Long, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });
 
// 第三步，去除RDD中每个key的随机前缀。
JavaPairRDD<Long, Long> removedRandomPrefixRdd = localAggrRdd.mapToPair(
        new PairFunction<Tuple2<String,Long>, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<Long, Long> call(Tuple2<String, Long> tuple)
                    throws Exception {
                long originalKey = Long.valueOf(tuple._1.split("_")[1]);
                return new Tuple2<Long, Long>(originalKey, tuple._2);
            }
        });
 
// 第四步，对去除了随机前缀的RDD进行全局聚合。
JavaPairRDD<Long, Long> globalAggrRdd = removedRandomPrefixRdd.reduceByKey(
        new Function2<Long, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });
```

解决方案五：将reduce join转为map join

**方案适用场景**：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。

**方案实现思路**：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。

**方案实现原理**：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。**方案优点**：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。**方案缺点**：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。

![img](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241624829.png)

```java

// 首先将数据量比较小的RDD的数据，collect到Driver中来。
List<Tuple2<Long, Row>> rdd1Data = rdd1.collect()
// 然后使用Spark的广播功能，将小RDD的数据转换成广播变量，这样每个Executor就只有一份RDD的数据。
// 可以尽可能节省内存空间，并且减少网络传输性能开销。
final Broadcast<List<Tuple2<Long, Row>>> rdd1DataBroadcast = sc.broadcast(rdd1Data);
 
// 对另外一个RDD执行map类操作，而不再是join类操作。
JavaPairRDD<String, Tuple2<String, Row>> joinedRdd = rdd2.mapToPair(
        new PairFunction<Tuple2<Long,String>, String, Tuple2<String, Row>>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, Tuple2<String, Row>> call(Tuple2<Long, String> tuple)
                    throws Exception {
                // 在算子函数中，通过广播变量，获取到本地Executor中的rdd1数据。
                List<Tuple2<Long, Row>> rdd1Data = rdd1DataBroadcast.value();
                // 可以将rdd1的数据转换为一个Map，便于后面进行join操作。
                Map<Long, Row> rdd1DataMap = new HashMap<Long, Row>();
                for(Tuple2<Long, Row> data : rdd1Data) {
                    rdd1DataMap.put(data._1, data._2);
                }
                // 获取当前RDD数据的key以及value。
                String key = tuple._1;
                String value = tuple._2;
                // 从rdd1数据Map中，根据key获取到可以join到的数据。
                Row rdd1Value = rdd1DataMap.get(key);
                return new Tuple2<String, String>(key, new Tuple2<String, Row>(value, rdd1Value));
            }
        });
 
// 这里得提示一下。
// 上面的做法，仅仅适用于rdd1中的key没有重复，全部是唯一的场景。
// 如果rdd1中有多个相同的key，那么就得用flatMap类的操作，在进行join的时候不能用map，而是得遍历rdd1所有数据进行join。

```

- 解决方案六：采样倾斜key并分拆join操作

**方案适用场景**：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。

**方案实现思路**：

- 对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。
- 然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。
- 接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。
- 再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。
- 而另外两个普通的RDD就照常join即可。
- 最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。

**方案实现原理**：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。具体原理见下图。

**方案优点**：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。

**方案缺点**：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241626975.png" alt="img" style="zoom:67%;" />

```java
// 首先从包含了少数几个导致数据倾斜key的rdd1中，采样10%的样本数据。
JavaPairRDD<Long, String> sampledRDD = rdd1.sample(false, 0.1);
 
// 对样本数据RDD统计出每个key的出现次数，并按出现次数降序排序。
// 对降序排序后的数据，取出top 1或者top 100的数据，也就是key最多的前n个数据。
// 具体取出多少个数据量最多的key，由大家自己决定，我们这里就取1个作为示范。
JavaPairRDD<Long, Long> mappedSampledRDD = sampledRDD.mapToPair(
        new PairFunction<Tuple2<Long,String>, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<Long, Long> call(Tuple2<Long, String> tuple)
                    throws Exception {
                return new Tuple2<Long, Long>(tuple._1, 1L);
            }     
        });
JavaPairRDD<Long, Long> countedSampledRDD = mappedSampledRDD.reduceByKey(
        new Function2<Long, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });
JavaPairRDD<Long, Long> reversedSampledRDD = countedSampledRDD.mapToPair( 
        new PairFunction<Tuple2<Long,Long>, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<Long, Long> call(Tuple2<Long, Long> tuple)
                    throws Exception {
                return new Tuple2<Long, Long>(tuple._2, tuple._1);
            }
        });
final Long skewedUserid = reversedSampledRDD.sortByKey(false).take(1).get(0)._2;
 
// 从rdd1中分拆出导致数据倾斜的key，形成独立的RDD。
JavaPairRDD<Long, String> skewedRDD = rdd1.filter(
        new Function<Tuple2<Long,String>, Boolean>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2<Long, String> tuple) throws Exception {
                return tuple._1.equals(skewedUserid);
            }
        });
// 从rdd1中分拆出不导致数据倾斜的普通key，形成独立的RDD。
JavaPairRDD<Long, String> commonRDD = rdd1.filter(
        new Function<Tuple2<Long,String>, Boolean>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2<Long, String> tuple) throws Exception {
                return !tuple._1.equals(skewedUserid);
            } 
        });
 
// rdd2，就是那个所有key的分布相对较为均匀的rdd。
// 这里将rdd2中，前面获取到的key对应的数据，过滤出来，分拆成单独的rdd，并对rdd中的数据使用flatMap算子都扩容100倍。
// 对扩容的每条数据，都打上0～100的前缀。
JavaPairRDD<String, Row> skewedRdd2 = rdd2.filter(
         new Function<Tuple2<Long,Row>, Boolean>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2<Long, Row> tuple) throws Exception {
                return tuple._1.equals(skewedUserid);
            }
        }).flatMapToPair(new PairFlatMapFunction<Tuple2<Long,Row>, String, Row>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Iterable<Tuple2<String, Row>> call(
                    Tuple2<Long, Row> tuple) throws Exception {
                Random random = new Random();
                List<Tuple2<String, Row>> list = new ArrayList<Tuple2<String, Row>>();
                for(int i = 0; i < 100; i++) {
                    list.add(new Tuple2<String, Row>(i + "_" + tuple._1, tuple._2));
                }
                return list;
            }
 
        });
 
// 将rdd1中分拆出来的导致倾斜的key的独立rdd，每条数据都打上100以内的随机前缀。
// 然后将这个rdd1中分拆出来的独立rdd，与上面rdd2中分拆出来的独立rdd，进行join。
JavaPairRDD<Long, Tuple2<String, Row>> joinedRDD1 = skewedRDD.mapToPair(
        new PairFunction<Tuple2<Long,String>, String, String>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, String> call(Tuple2<Long, String> tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(100);
                return new Tuple2<String, String>(prefix + "_" + tuple._1, tuple._2);
            }
        })
        .join(skewedUserid2infoRDD)
        .mapToPair(new PairFunction<Tuple2<String,Tuple2<String,Row>>, Long, Tuple2<String, Row>>() {
                        private static final long serialVersionUID = 1L;
                        @Override
                        public Tuple2<Long, Tuple2<String, Row>> call(
                            Tuple2<String, Tuple2<String, Row>> tuple)
                            throws Exception {
                            long key = Long.valueOf(tuple._1.split("_")[1]);
                            return new Tuple2<Long, Tuple2<String, Row>>(key, tuple._2);
                        }
                    });
 
// 将rdd1中分拆出来的包含普通key的独立rdd，直接与rdd2进行join。
JavaPairRDD<Long, Tuple2<String, Row>> joinedRDD2 = commonRDD.join(rdd2);
 
// 将倾斜key join后的结果与普通key join后的结果，uinon起来。
// 就是最终的join结果。
JavaPairRDD<Long, Tuple2<String, Row>> joinedRDD = joinedRDD1.union(joinedRDD2);
```

解决方案七：使用随机前缀和扩容RDD进行join

**方案适用场景**：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。

**方案实现思路**：

- 该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。
- 然后将该RDD的每条数据都打上一个n以内的随机前缀。
- 同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条-数据都依次打上一个0~n的前缀。
- 最后将两个处理后的RDD进行join即可。

**方案实现原理**：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。

**方案优点**：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。

**方案缺点**：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。

**方案实践经验**：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。

```java
// 首先将其中一个key分布相对较为均匀的RDD膨胀100倍。
JavaPairRDD<String, Row> expandedRDD = rdd1.flatMapToPair(
        new PairFlatMapFunction<Tuple2<Long,Row>, String, Row>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Iterable<Tuple2<String, Row>> call(Tuple2<Long, Row> tuple)
                    throws Exception {
                List<Tuple2<String, Row>> list = new ArrayList<Tuple2<String, Row>>();
                for(int i = 0; i < 100; i++) {
                    list.add(new Tuple2<String, Row>(0 + "_" + tuple._1, tuple._2));
                }
                return list;
            }
        });
 
// 其次，将另一个有数据倾斜key的RDD，每条数据都打上100以内的随机前缀。
JavaPairRDD<String, String> mappedRDD = rdd2.mapToPair(
        new PairFunction<Tuple2<Long,String>, String, String>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, String> call(Tuple2<Long, String> tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(100);
                return new Tuple2<String, String>(prefix + "_" + tuple._1, tuple._2);
            }
        });
 
// 将两个处理后的RDD进行join即可。
JavaPairRDD<String, Tuple2<String, Row>> joinedRDD = mappedRDD.join(expandedRDD);
```

解决方案八：多种方案组合使用

在实践中发现，很多情况下，如果只是处理较为简单的数据倾斜场景，那么使用上述方案中的某一种基本就可以解决。但是如果要处理一个较为复杂的数据倾斜场景，那么可能需要将多种方案组合起来使用。比如说，我们针对出现了多个数据倾斜环节的Spark作业，可以先运用解决方案一和二，预处理一部分数据，并过滤一部分数据来缓解；其次可以对某些shuffle操作提升并行度，优化其性能；最后还可以针对不同的聚合或join操作，选择一种方案来优化其性能。大家需要对这些方案的思路和原理都透彻理解之后，在实践中根据各种不同的情况，灵活运用多种方案，来解决自己的数据倾斜问题。

## 二、 HDFS文件块为什么设置成128M

1. 如果块设置过大，

   一方面，从磁盘传输数据的时间会明显大于寻址时间，导致程序在处理这块数据时，变得非常慢；

   另一方面，mapreduce中的map任务通常一次只处理一个块中的数据，如果块过大运行速度也会很慢。

2. 如果块设置过小，

   一方面存放大量小文件会占用NameNode中大量内存来存储元数据，而NameNode的内存是有限的，不可取；

   另一方面文件块过小，寻址时间增大，导致程序一直在找block的开始位置。

   ```
   1. HDFS中平均寻址时间大概为10ms；
   2. 经过前人的大量测试发现，寻址时间为传输时间的1%时，为最佳状态；
   所以最佳传输时间为10ms/0.01=1000ms=1s
   3. 目前磁盘的传输速率普遍为100MB/s；
   计算出最佳block大小：100MB/s x 1s = 100MB
   所以我们设定block大小为128MB。
   ```

## 三、 HDFS写数据过程，写的过程中有哪些故障，分别会怎么处理?

1. 如果DN收到一半 DN挂了的处理流程：
  客户端每读取64K的数据，封装为一个packet，封装成功的packet，放入到一个队列中，这个队列称为dataQuene(待发送数据包)在发送时，先将dataQuene中的packet按顺序发送，发送后再放入到ackquene(正在发送的队列)。每个节点在收到packet后，向客户端发送ack确认消息！当所有DN都发送ack，客户端收到这些ack后，传输成功，ackquene删除掉这个packet。假如一个packet在发送后，在收到DN返回的ack确认消息时超时，传输中止，将此时所有DN中正在传输的packet剔除，ackquene中的packet会回滚到dataQuene。重新建立通道，剔除坏的DN节点，包括里面的所有信息。建立完成之后，继续传输！只要有一个DN节点收到了数据，DN上报NN已经收完此块，NN就认为当前块已经传输成功！NN会自动维护副本数！

2. 读取文件时DN挂了
  DataNode 挂了只需要失败转移到其他副本所在的 DataNode 继续读取
3. 读取到的文件数据损坏
读取到的文件数据块若校验失败可认定为损坏，依然可以转移到读取其他完好的副本，并向 NameNode 汇报该文件 block 损坏，后续处理由 NameNode 通知 DataNode 删除损坏文件 block，并根据完好的副本来复制一份新的文件 block 副本。

## 四、 Spark面试题
### 1. Spark为什么比MapReduce快？

1. spark是基于内存进行数据处理的，MapReduce是基于磁盘进行数据处理的。MapReduce的设计：中间结果保存在文件中，提高了可靠性，减少了内存占用。但是牺牲了性能。
   Spark的设计：数据在内存中进行交换，要快一些，但是内存这个东西，可靠性不如磁盘。所以性能方面比MapReduce要好。
   DAG计算模型在迭代计算上还是比MapReduce的效率更高。
2. Spark中**具有DAG有向无环图**，DAG有向无环图在此过程中**减少了shuffle以及落地磁盘的次数**
  Spark 计算比 MapReduce 快的根本原因在于 DAG 计算模型。一般而言，DAG 相比MapReduce 在大多数情况下可以减少 shuffle 次数。Spark 的 DAGScheduler 相当于一个改进版的 MapReduce，如果计算不涉及与其他节点进行数据交换，Spark 可以在内存中一次性完成这些操作，也就是中间结果无须落盘，减少了磁盘 IO 的操作。但是，如果计算过程中涉及数据交换，Spark 也是会把 shuffle 的数据写磁盘的！有一个误区，Spark 是基于内存的计算，所以快，这不是主要原因，要对数据做计算，必然得加载到内存，Hadoop 也是如此，只不过 Spark 支持将需要反复用到的数据给 Cache 到内存中，减少数据加载耗时，所以 Spark 跑机器学习算法比较在行（需要对数据进行反复迭代）。Spark 基于磁盘的计算也是比 Hadoop 快。刚刚提到了 Spark 的 DAGScheduler 是个改进版的 MapReduce，所以 Spark天生适合做批处理的任务。Hadoop 的 MapReduce 虽然不如 spark 性能好，但是 HDFS 仍然是业界的大数据存储标准。
3. spark是粗粒度资源申请，也就是当提交spark application的时候，application会将所有的资源申请完毕，如果申请不到资源就等待，如果申请到资源才执行application，task在执行的时候就不需要自己去申请资源，task执行快，当最后一个task执行完之后task才会被释放。

  优点是执行速度快，缺点是不能使集群得到充分的利用

  MapReduce是细粒度资源申请，当提交application的时候，task执行时，自己申请资源，自己释放资源，task执行完毕之后，资源立即会被释放，task执行的慢，application执行的相对比较慢。

  优点是集群资源得到充分利用，缺点是application执行的相对比较慢。

  Spark是基于内存的，而MapReduce是基于磁盘的迭代

### 2. Spark的RDD、DataFrame、DataSet、DataStream区别?

RDD叫做弹性分布数据集，是Spark中最基本的**数据处理模型**。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面元素可并行计算的集合。

![image-20220913123524315](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/image-20220913123524315.png)

在 Spark 中，DataFrame 是一种以 RDD 为基础的分布式数据集，类似于传统数据库中的二维表格。DataFrame 与 RDD 的主要区别在于，前者带有 schema 元信息，即 DataFrame所表示的二维表数据集的每一列都带有名称和类型。

DataSet是分布式数据集合。DataSet是Spark 1.6中添加的一个新抽象，是DataFrame的一个扩展。它提供了RDD的优势（强类型，使用强大的lambda函数的能力）以及Spark SQL优化执行引擎的优点。DataFrame=DataSet[Row]。

###  3. Spark的stage如何划分?在源码中是怎么判断属于Shuffle Map Stage或Result Stage的? DAG划分Spark源码实现?

遇到宽依赖（shuffle RDD）划分一个Stage，遇到一个行动算子划分一个Job。

源码中，运行了Action算子后，DAGScheduler会提交job，创建一个finalStage，这个stage是ResultStage（一个Job里面只有最后一个stage是ResultStage，其余的都是ShuffleMapStage），然后创建Job（里面包含了Job的一些信息），并将Job的相关信息放入缓存中，接着就创建了比较重要的submitStage(finalStage)方法，这个方法里面就包含了stage的划分和提交；而submitWaitingStages()则是提交剩余的stage。stage的划分通过getMissingParentStages()方法来实现，首先根据当前这个stage找到它的父stage，假如父stage的RDD与当前stage的RDD是宽依赖的关系，那么就用这个宽依赖的RDD创建一个ShuffleMapStage，并返回；假如不存在宽依赖，那么就一直遍历下去，直到第一个RDD为止。为了防止栈溢出，getMissingParentStages()使用了一个stack结构waitingForVisit，我们看内部函数visit()方法，它会遍历当前RDD的依赖，假如存在shuffle依赖，那么就创建一个ShuffleMapStage，并返回，否则就一直执行下去，直到没有父RDD为止，这也就意味着整个Job只创建了一个Stage（ResultStage）。

  **总结一下，stage的划分是以shuffle为界，也即宽依赖，如果RDD之间发生了shuffle，那么就会以shuffle为界创建新的stage，依次内推。而stage的提交是递归提交，最先创建的stage，会最后提交，这刚好符合RDD的处理流程的先后顺序。**

### 4. Spark的内存模型?

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20210919162741257.png" alt="img" style="zoom:50%;" />

spark堆外：（之所以叫spark堆外，是因为后续要和jvm堆外进行区别，也是大家容易弄混淆的地方），为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间。Spark 可以直接操作堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。当需要缓存非常多GB的数据时可以考虑使用堆外内存，将数据缓存的工作交给堆外降低Java垃圾收集器带来的压力。

在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。

堆外内存由于默认不开启堆外内存，以及笔者没有使用堆外内存的客观收益证明，这里不进行详细讨论

spark堆内：spark 堆内内存就是spark提交给jvm管理的那部分内存（与直接操作系统内存对应），spark 对堆内内存的管理是一种逻辑上的"规划式"的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存。这也是为什么堆内占用没法被精确计算（非序列化的对象），以及内存使用情况无法精确得知（无法清楚得知jvm的GC情况）的原因。

spark堆内内存模型示意图

![img](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20210919162838880.png)

如图所示，spark.{executor/driver}.memory参数来设置堆内存， spark.yarn.{executor/driver}.memoryOverhead 来设置堆外内存。

（注意：这里的memoryOverhead所指的堆外内存是jvm控制的堆外内存，与上面说的spark堆外内存不是一回事）

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20210919162922718.png" alt="img" style="zoom:50%;" />

Execution 内存：主要用于存放 Shuffle、Join、Sort、Aggregation 等计算过程中的临时数据

Storage 内存：主要用于存储 spark 的 cache 数据，例如RDD的缓存、unroll数据；

用户内存（User Memory）：主要用于存储 RDD 转换操作所需要的数据，例如 RDD 依赖等信息，对于sparkSQL而言还有UDF的内存占用。注意：这部分数据无法spill到磁盘，如果不够就会OOM

预留内存（Reserved Memory）：系统预留内存，会用来存储Spark内部对象。

（注意：公司集群中，spark.memory.fraction的默认值是0.3）



### 5. Spark/RDD的容错

RDD不同的依赖关系导致Spark对不同的依赖关系有不同的处理方式。

对于宽依赖而言，由于宽依赖实质是指父RDD的一个分区会对应一个子RDD的多个分区，在此情况下出现部分计算结果丢失，单一计算丢失的数据无法达到效果，便采用重新计算该步骤中的所有数据，从而会导致计算数据重复；对于窄依赖而言，由于窄依赖实质是指父RDD的分区最多被一个子RDD使用，在此情况下出现部分计算的错误，由于计算结果的数据只与依赖的父RDD的相关数据有关，所以不需要重新计算所有数据，只重新计算出错部分的数据即可。

Spark框架层面的容错机制，主要分为三大层面（调度层、RDD血统层、Checkpoint层），在这三大层面中包括Spark RDD容错四大核心要点。

　　（1）Stage输出失败，上层调度器DAGScheduler重试。
　　（2）Spark计算中，Task内部任务失败，底层调度器重试。
　　（3）RDD Lineage血统中窄依赖、宽依赖计算。
　　（4）Checkpoint缓存。

（1）Stage输出失败，上层调度器DAGScheduler会进行重试。 对之前获取所有失败的Stage，根据jobId排序后逐一重试

（2）Spark计算过程中，计算内部某个Task任务出现失败，底层调度器会对此Task进行若干次重试（默认4次）。

（3）Spark中RDD采用高度受限的分布式共享内存，且新的RDD的产生只能够通过其他RDD上的批量操作来创建，依赖于以RDD的Lineage为核心的容错处理，在迭代计算方面比Hadoop快20多倍，同时还可以在5～7s内交互式地查询TB级别的数据集。

　　Spark RDD实现基于Lineage的容错机制，基于RDD的各项transformation构成了compute chain，在部分计算结果丢失的时候可以根据Lineage重新恢复计算。

（4）Spark checkpoint通过将RDD写入Disk作检查点，是Spark lineage容错的辅助，lineage过长会造成容错成本过高，这时在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区，从做检查点的RDD开始重做Lineage，就会减少开销。

　　checkpoint主要适用于以下两种情况：

　　（1）DAG中的Lineage过长，如果重算，开销太大，如PageRank、ALS等。
　　（2）尤其适合在宽依赖上作checkpoint，这个时候就可以避免为Lineage重新计算而带来的冗余计算。

### 6. RDD的缓存级别?

​	Cache缓存：RDD通过Cache或者Persist方法将前面的计算结果缓存，默认情况下会把数据缓存在**内存**中。但是这两个方法被调用时并不会立即缓存，而是触发后面的action[算子](https://so.csdn.net/so/search?q=算子&spm=1001.2101.3001.7020)时，该RDD将会被缓存到计算节点的内存中，提供给后面的算子重用。

​	Persist缓存：persist()方法可控制缓存级别

```
说明：
NONE： 不存储
DISK_ONLY : 只保存在磁盘中
DISK_ONLY_2 : 只保存在磁盘中,数据保存两份
MEMORY_ONLY ： 只保存在内存中
MEMORY_ONLY_2 ： 只保存在内存中,数据保存两份
MEMORY_ONLY_SER ：只保存在内存中,以序列化形式存储
MEMORY_ONLY_SER_2 ： 只保存在内存中,以序列化形式存储，数据保存两份
MEMORY_AND_DISK ： 数据保存在内存/磁盘中,可以动态调整
MEMORY_AND_DISK_2 ： 数据保存在内存/磁盘中,可以动态调整，数据保存两份
MEMORY_AND_DISK_SER ：数据保存在内存/磁盘中,可以动态调整,以序列化形式存储
MEMORY_AND_DISK_SER_2 ： 数据保存在内存/磁盘中,可以动态调整,以序列化形式存储，数据保存两份
OFF_HEAP ：数据保存在堆外内存中
常用：
MEMORY_ONLY<只适用于小数据量场景>
MEMORY_AND_DISK<适用于大数据量场景>
```

​	CheckPoint检查点：其实就是通过将RDD中间结果写入磁盘（比如分布式文件系统HDFS），同时切断RDD之间的血缘关系。

```
由于血缘关系过长会造成容错成本过高，就可以在中间阶段做checkpoint容错，如果checkpoint之后有节点出现问题，就可以从checkpoint开始重做血缘，减少开销。
checkpoint操作之后也是不会马上被执行，必须执行action算子后才能触发。
checkpoint需要指定保存路径，当作业执行完成时，路径中保存的文件是不会被删除的。
```

​	三个缓存算子的区别：

```
1、cache和persist只是将数据保存起来，不会切断血缘依赖；而checkpoint会切断RDD之间的血缘依赖。

2、cache是将数据临时保存在内存中进行数据重用，可靠性低；

persist是可以将数据临时保存在磁盘文件或者内存中进行数据重用，作业执行完毕，临时保存的文件就会丢失，可靠性低；

checkpoint是将数据永久保存在HDFS等容错、高可用的文件系统，可靠性高。

3、建议对某个RDD执行checkpoint之前，对该RDD执行cache，这样checkpoint的job只需从cache缓存中读取数据并上传到HDFS中即可，不需要重新计算。

4、如果使用完了缓存，可以通过unpersist()方法释放缓存

5、三个算子属于持久化算子，不属于转换算子和行动算子
```

### 7. Spark广播变量的实现和原理?

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208051612709.png" style="zoom:33%;" />

广播变量，初始的时候，就在Drvier上有一份副本。task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；如果本地没有，那么就从Driver远程拉取变量副本，并保存在本地的BlockManager中；此后这个executor上的task，都会直接使用本地的BlockManager中的副本。executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本。

### 8. DAGScheduler是什么？

DAGScheduler是任务调度中的其中一个环节，是任务调度的第一步。DAGScheduler是Spark的较高层次的调度器，它实现了面向Stage（stage-oriented）的调度。它把一个通过RDD的转换操作（RDD Transformations）得到的血缘关系（RDD Lineage）转化成多个Stage，然后为每个Stage生成一个任务集（TaskSet），并把该任务集交给TaskScheduler处理。

```
具体来说DAGScheduler的功能如下：
1.划分和创建Stage：根据RDD之间的依赖类型（窄依赖或宽依赖），为每个Job划分和创建Stage，多个Stage之间相互依赖，形成一个DAG（有向无环图）。
2.决定运行Task的最佳位置：根据RDD的依赖关系，缓存或Shuffling数据的位置来计算运行Task的最佳位置。
3.为每个Stage创建一个TaskSet，并把TaskSet作为参数传递给TaskScheduler。
4.处理失败的Stage：为了从失败中恢复，同样的Stage可能会提交多次。例如：由于前一个Stage的map输出文件丢失，TaskScheduler报告了一个任务失败，DAGScheduler会重新提交丢失的Stage。这是通过一个带有FetchFailed或ExecutorLost的CompletionEvent事件检测到的。DAGScheduler将等待一小段时间以查看其他节点或任务是否失败，然后为任何缺失的Stage重新提交TaskSet。
5.当任务运行完成后，清空所有的缓存和临时数据。
6.处理各种事件，包括内部的事件，也包括Executor端的状态更新等事件。
```

### 9. Spark的几种部署方式及好处

1. local模式

```
Spark 不一定非要跑在 hadoop 集群，可以在本地，起多个线程的方式来指
定。将 Spark 应用以多线程的方式直接运行在本地，一般都是为了方便调试， 本地模式分三类
local:只启动一个 executor
local[k]:启动 k 个 executor
local[*]:启动跟 cpu 数目相同的 executor
一般用于教学、调试、演示。
```

2. StandAlone模式

```
分布式部署集群，自带完整的服务，资源管理和任务监控是 Spark 自己监控， 这个模式也是其他模式的基础。StandAlone模式由Spark自身提供计算资源，无需其他框架提供资源。这种方式降低了和其他第三方资源框架的耦合性，独立性很强。
```

3. Yarn模式

```
分布式部署集群，资源和任务监控交给 yarn 管理，但是目前仅支持粗粒度资源分配方式，包含 cluster 和 client 运行模式，cluster 适合生产，driver 运行 在集群子节点，具有容错功能，client 适合调试，dirver 运行在客户端。
这种模式部署Application
1.部署Application和服务更加方便
只需要yarn服务，包括Spark，Storm在内的多种应用程序不要要自带服务，它们经由客户端提交后，由yarn提供的分布式缓存机制分发到各个计算节点上。
2.资源隔离机制
yarn只负责资源的管理和调度，完全由用户和自己决定在yarn集群上运行哪种服务和Applicatioin，所以在yarn上有可能同时运行多个同类的服务和Application。Yarn利用Cgroups实现资源的隔离，用户在开发新的服务或者Application时，不用担心资源隔离方面的问题。
3.资源弹性管理
Yarn可以通过队列的方式，管理同时运行在yarn集群种的多个服务，可根据不同类型的应用程序压力情况，调整对应的资源使用量，实现资源弹性管理。
```

4. Spark On K8S & Mesos 模式

```
官方推荐这种模式(当然，原因之一是血缘关系)。正是由于 Spark 开发之 初就考虑到支持 Mesos，因此，目前而言，Spark 运行在 Mesos 上会比运行 在 YARN 上更加灵活，更加自然。用户可选择两种调度模式之一运行自己的应 用程序：

(1)粗粒度模式(Coarse-grained Mode):每个应用程序的运行环境由 一个 Dirver 和若干个 Executor 组成，其中，每个 Executor 占用若干资源， 内部可运行多个 Task(对应多少个“slot”)。应用程序的各个任务正式运行 之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资 源，即使不用，最后程序运行结束后，回收这些资源。

(2)细粒度模式(Fine-grained Mode):鉴于粗粒度模式会造成大量资源 浪费，Spark On Mesos 还提供了另外一种调度模式:细粒度模式，这种模式 类似于现在的云计算，思想是按需分配。
```

### 10. Spark Streaming的工作原理?

Spark Streaming内部的基本工作原理如下：接收实时输入数据流，然后将数据拆分成多个batch，比如每收集1秒的数据封装为一个batch，然后将每个batch交给Spark的计算引擎进行处理，最后会生产出一个结果数据流，其中的数据，也是由一个一个的batch所组成的。

![在这里插入图片描述](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20190214161337540.png)

```
从图中也能看出它将输入的数据分成多个batch进行处理，严格来说spark streaming 并不是一个真正的实时框架,因为他是分批次进行处理的
```

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20190221160101615.png" alt="在这里插入图片描述" style="zoom:150%;" />

### 11. Spark Streaming的DStream和DStreamGraph的区别?  

DStreamGraph相当于定义很多Dstream，中间用操作穿起来，构成了DStream之间的依赖关系。

### 12. 介绍下Spark Streaming和Structed Streaming

Structed Streaming基于sql开发，入口是sparksession，使用的统一Dataset数据集，数据的操作会使用sql自带的优化策略实现Structured Streaming将实时数据当做**被连续追加的表**。流上的每一条数据都类似于将一行新数据添加到表中。

### 13. Spark Streaming的双流join的过程，怎么做的?

举例：拿一个流是订单数据，另一个流是订单详情数据来说，要实现这两条流的join操作

首先，join方式要选择full outer join，保证不会因为数据批次不同而漏掉可连接的数据。

其次，使用redis对数据进行缓存。分析两个数据流的对应情况，一个订单数据一般会对应多个订单详情数据，redis对订单数据和订单详情数据进行缓存，其中，订单详情数据因为数据量大，所以一旦join上以后会清除缓存中的数据；而订单数据也不需要无限保存下去，只需要等待一段时间则可进行删除，因为要确保实时性，缓存时间太长也就没有意义。所以，使用redis管理这些数据的生命周期。

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20201024114539537.png" alt="在这里插入图片描述" style="zoom: 67%;" />

### 14. Spark Streaming怎么保证数据不丢失

对于文件这样的源数据，这个driver恢复机制足以做到零数据丢失，因为所有的数据都保存在了像HDFS或S3这样的容错文件系统中了，遇到数据错误时按照普通的RDD容错机制，如血缘依赖、Checkpoint持久化就可以解决。而对于kafka中的数据，则需要分接收方法不同来解决：

1. Receiver方式为确保零数据丢失，必须在Spark Streaming中另外启用预写日志（Write Ahead Logs）。这将同步保存所有收到的Kafka数据到分布式文件系统（例如HDFS）上，以便在发生故障时可以恢复所有数据。
2. Direct方式依靠checkpoint机制来保证。每次streaming 消费了kafka的数据后，将消费的kafka offsets更新到checkpoint。当你的程序挂掉或者升级的时候，就可以接着上次的读取，实现数据的零丢失。

### 15. Spark Streaming怎么实现数据持久化保存?

```
与RDD类似，Spark Streaming也可以让开发人员手动控制，将数据流中的数据持久化到内存中。对DStream调用persist()方法，就可以让Spark Streaming自动
将该数据流中的所有产生的RDD，都持久化到内存中。如果要对一个DStream多次执行操作，那么，对DStream持久化是非常有用的。因为多次操作，可以共享
使用内存中的一份缓存数据。

对于基于窗口的操作，比如reduceByWindow、reduceByKeyAndWindow，以及基于状态的操作，比如updateStateByKey，默认就隐式开启了持久化机制。即Spark Streaming默认就会将上述操作产生的Dstream中的数据，缓存到内存中，不需要开发人员手动调用persist()方法。

对于通过网络接收数据的输入流，比如socket、Kafka、Flume等，默认的持久化级别，是将数据复制一份，以便于容错。相当于是，用的是类似MEMORY_ONLY_SER_2。

与RDD不同的是，默认的持久化级别，统一都是要序列化的。

每一个Spark Streaming应用，正常来说，都是要7 * 24小时运转的，这就是实时计算程序的特点。因为要持续不断的对数据进行计算。因此，对实时计算应用的要求，应该是必须要能够对与应用程序逻辑无关的失败，进行容错。

如果要实现这个目标，Spark Streaming程序就必须将足够的信息checkpoint到容错的存储系统上，从而让它能够从失败中进行恢复。有两种数据需要被进行checkpoint：

1、元数据checkpoint——将定义了流式计算逻辑的信息，保存到容错的存储系统上，比如HDFS。当运行Spark Streaming应用程序的Driver进程所在节点失败时，该信息
可以用于进行恢复。元数据信息包括了：
  1.1 配置信息——创建Spark Streaming应用程序的配置信息，比如SparkConf中的信息。
  1.2 DStream的操作信息——定义了Spark Stream应用程序的计算逻辑的DStream操作信息。
  1.3 未处理的batch信息——那些job正在排队，还没处理的batch信息。

2、数据checkpoint——将实时计算过程中产生的RDD的数据保存到可靠的存储系统中。

对于一些将多个batch的数据进行聚合的，有状态的transformation操作，这是非常有用的。在这种transformation操作中，生成的RDD是依赖于之前的batch的RDD的，
这会导致随着时间的推移，RDD的依赖链条变得越来越长。

要避免由于依赖链条越来越长，导致的一起变得越来越长的失败恢复时间，有状态的transformation操作执行过程中间产生的RDD，会定期地被checkpoint到可靠的存储系统上，比如HDFS。从而削减RDD的依赖链条，进而缩短失败恢复时，RDD的恢复时间。

一句话概括，元数据checkpoint主要是为了从driver失败中进行恢复；
而RDD checkpoint主要是为了，使用到有状态的transformation操作时，能够在其生产出的数据丢失时，进行快速的失败恢复。
```

### 16. Spark SQL读取文件，内存不够使用，如何处理?

```
在Shuffle过程，reduce端task并不是等到map端task将其数据全部写入磁盘后再去拉取，而是map端写一点数据，reduce端task就会拉取一小部分数据，然后立即进行后面的聚合、算子函数的使用等操作。
reduce端task能够拉取多少数据，由reduce拉取数据的缓冲区buffer来决定，因为拉取过来的数据都是先放在buffer中，然后再进行后续的处理，buffer的默认大小为48MB。
reduce端task会一边拉取一边计算，不一定每次都会拉满48MB的数据，可能大多数时候拉取一部分数据就处理掉了。
虽然说增大reduce端缓冲区大小可以减少拉取次数，提升Shuffle性能，但是有时map端的数据量非常大，写出的速度非常快，此时reduce端的所有task在拉取的时候，有可能全部达到自己缓冲的最大极限值，即48MB，此时，再加上reduce端执行的聚合函数的代码，可能会创建大量的对象，这可难会导致内存溢出，即OOM。
如果一旦出现reduce端内存溢出的问题，我们可以考虑减小reduce端拉取数据缓冲区的大小，例如减少为12MB。
在实际生产环境中是出现过这种问题的，这是典型的以性能换执行的原理。reduce端拉取数据的缓冲区减小，不容易导致OOM，但是相应的，reudce端的拉取次数增加，造成更多的网络传输开销，造成性能的下降。
注意，要保证任务能够运行，再考虑性能的优化。
```

```
当SparkSQL的sql语句有成百上千的or关键字时，就可能会出现Driver端的JVM栈内存溢出。
JVM栈内存溢出基本上就是由于调用的方法层级过多，产生了大量的，非常深的，超出了 JVM 栈深度限制的递归。（我们猜测SparkSQL有大量or语句的时候，在解析SQL时，例如转换为语法树或者进行执行计划的生成的时候，对于or的处理是递归，or非常多时，会发生大量的递归）
此时，建议将一条sql语句拆分为多条sql语句来执行，每条sql语句尽量保证100个以内的子句。根据实际的生产环境试验，一条sql语句的or关键字控制在100个以内，通常不会导致JVM栈内存溢出
```

### 17. Spark的exactly-once

Spark Streaming的处理逻辑天生具备exactly once语义。
Spark RDD之所以被称为“弹性分布式数据集”，是因为它具有**不可变、可分区、可并行计算、容错**的特征。一个RDD只能由稳定的数据集生成，或者从其他RDD转换（transform）得来。如果在执行RDD lineage的过程中失败，那么只要源数据不发生变化，无论重新执行多少次lineage，都一定会得到同样的、确定的结果。

最后，我们还需要保证输出过程也符合exactly once语义。Spark Streaming的输出一般是靠foreachRDD()算子来实现，它默认是at least once的。如果输出过程中途出错，那么就会重复执行直到写入成功。为了让它符合exactly once，可以施加两种限制之一：**幂等性写入**（idempotent write）、**事务性写入**（transactional write）。

- **幂等性写入**
  幂等原来是数学里的概念，即f(f(x))=f(x)。幂等写入就是写入多次与写入一次的结果完全相同，可以自动将at least once转化为exactly once。这对于自带主键或主键组的业务比较合适（比如各类日志、MySQL binlog等），并且实现起来比较简单。
  但是它要求处理逻辑是map-only的，也就是只能包含转换、过滤等操作，不能包含shuffle、聚合等操作。如果条件更严格，就只能采用事务性写入方法。

- **事务性写入**
  这里的事务与DBMS中的事务含义基本相同，就是对数据进行一系列访问与更新操作所组成的逻辑块。为了符合事务的**ACID特性**，必须引入一个唯一ID标识当前的处理逻辑，并且将计算结果与该ID一起落盘。ID可以由主题、分区、时间、offset等共同组成。
  事务操作可以在foreachRDD()时进行。如果数据写入失败，或者offset写入与当前offset range不匹配，那么这一批次数据都将失败并且回滚。

### 18. Spark计算的灵活性？

Spark提供了不同层面的灵活性。在实现层，它完美演绎了Scala trait动态混入（mixin）策略（如可更换的集群调度器、序列化库）；在原语（Primitive）层，它允许扩展新的数据算子（operator）、新的数据源（如HDFS之外支持DynamoDB）、新的language bindings（Java和Python）；在范式（Paradigm）层，Spark支持内存计算、多迭代批量处理、即席查询、流处理和图计算等多种范式。

## 五、 Kafka面试题

### 1. 介绍下Kafka，Kafka的作用?Kafka的组件?适用场景?

Kafka是一个分布式的基于发布/订阅模式的消息队列(Message Queue)，主要应用于大数据实时处理领域。组件包括Producer、Consumer、Consumer Group、Broker、Topic、Partition、Replica、Leader、follower。

使用场景有：

- 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等。
- 消息系统：解耦和生产者和消费者、缓存消息等。
- 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
- 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
- 流式处理：比如spark streaming和 Flink

### 2. Kafka作为消息队列，它可解决什么样的问题?

1. 解耦

   允许独立扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束；

2. 可恢复性

   系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理；

3. 缓冲

   有助于控制和优化数据流过系统的速度，解决生产消息和消费消息的处理速度不一致的情况；

4. 灵活性和峰值处理能力

   在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃；

5. 异步通信

   用户有时不需要立即处理消息。消息队列提供了异步处理机制，允许用户把多个消息放入队列，但并不立即处理它。

### 3. Kafka的优缺点？

   优点

   - 支持多个生产者和消费者
   - 支持broker的横向拓展
   - 副本集机制，实现数据冗余，保证数据不丢失
   - 通过topic将数据进行分类
   - 通过分批发送压缩数据的方式，减少数据传输开销，提高吞吐量
   - 支持多种模式的消息
   - 基于磁盘实现数据的持久化
   - 高性能的处理信息，在大数据的情况下，可以保证亚秒级的消息延迟
   - 对资源的消耗比较小
   - 支持跨数据中心的数据复制
   - 支持镜像集群

   缺点

   - 由于是批量发送，数据并非真正的实时；
   - 对于mqtt协议不支持；
   - 仅支持统一分区内消息有序，无法实现全局消息有序；
   - 监控不完善，需要安装插件；
   - 依赖zookeeper进行元数据管理；
   - topic一般需要人工创建，部署和维护一般都比mq高。

### 4. Kafka相比于传统消息传递方式有什么优点？

**高性能**：单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作，Kafka性能远超过传统的ActiveMQ、RabbitMQ等，而且Kafka支持Batch操作；
**可扩展**：Kafka集群可以透明的扩展，增加新的服务器进集群；
**容错性**： Kafka每个Partition数据会复制到几台服务器，当某个Broker失效时，Zookeeper将通知生产者和消费者从而使用其他的Broker

### 5. Kafka怎么保证数据的可靠性？

可靠性 = 数据不丢失 + 数据一致性

数据不丢失：ack机制，数据一致性：LEO和ISR机制

### 6. Kafka如何保证全局有序?

```
全局使用一个生产者 
全局使用一个消费者（并严格到一个消费线程） 
全局使用一个分区（当然不同的表可以使用不同的分区或者topic实现隔离与扩展）
```

这样做效率极低

比如
在1个topic中，有3个partition，那么如何保证数据的消费？

比如可以以订单ID作为key,然后取Hash,那么订单ID相同的一定会分到同一分区.
同一分区的数据如果只有一个消费者单线程消费,那么一定也是有序的.
同一分区的数据如果有多个线程消费，就需要写N个queue，将具有相同key的数据都存储在同一个queue，然后对于N个线程，每个线程分别消费一个queue即可。

### 7. 生产者消费者模式与发布订阅模式有何异同?

生产者/消费者模式是一对一消费，生产者生产消息到队列中，消费中从队列中消费消息，消息被消费完以后从队列中删除，其他消费者无法消费。一个队列支持多个消费者进行消费，但对一个消息只有一个消费者可以消费。

发布/订阅模式是生产者将消息发布到topic中，同时有多个消费者消费该消息，和点对点模式不同，发布到topic的消息可被所有消费者消费。

### 8. Kafka中为什么同一个消费者组的消费者不能消费相同的分区？
消费者拉取消息需要提供offset, limit。
如果offset放在broker端，那么一定会产生额外的通信开销；
如果offset放在Consumer端，如果在一个组有多个消费者，就需要有一个协调者，集中式的管理，解决锁冲突，如果不解决冲突，那么势必会产生**重复消费**、无用的消费，从而导致资源浪费。
kafka已经实现分布式消费，多个消费组同时消费同一个分区就可以，处于权衡目的，没有再细化到消费组内再分布消费。

### 9. Kakfa中的offset

**Current offset**

- Current offset 保存在客户端中由客户端自己维护，它表示消费者希望收到下一条消息的序号，它仅仅在poll()方法中使用，例如：消费者第一次调用poll()方法收到了20条消息，那么 current offset的值将被设置成20 下一次poll时，kafka就知道要从序号为21的消息开始读取，这样能保证消费者每次poll消息时，收到的消息不重复 

​    **Committed offset**

- Committed Offset保存在Broker上 (V0.9之后的版本)，它表示Consumer已经确认消费过的消息的序号。主要通过commitSync()来操作。举例:Consumer通过poll()方法收到20条消息后，此时Current Offset就是20，经过一系列的逻辑处理后，并没有调用commitSync()来提交Committed Offset，那么此时Committed Offset依旧是0。
- Committed Offset主要用于Consumer Rebalance(再平衡)。在Consumer Rebalance的过程中，一个Partition被分配给了一个Consumer，那么这个Consumer该从什么位置开始消费消息呢?答案就是Committed Offset。另外，如果一个Consumer消费了5条消息.(poll并且成功commitSync)之后宕机了，重新启动之后，它仍然能够从第6条消息开始消费，因为Committed Offset已经被Kafka记录为5。
- Committed Offset是为了每一个消费组进行记录的 不同的消费者组分别记录

Current offset 是针对消费者 poll过程为了保证每次poll都返回不重复的消息

Committed offset 是为了 Consumer Rebalance(再平衡) 的你过程，它能够保证同一个消费者组中新的消费者在正确的位置开始消费，避免重复消费。

### 10. Kafka支持什么语义？怎么实现ExactlyOnlyOnce?

**生产者-Broker：**

ack机制+ExactlyOnlyOnce

at-most-once ： ack = 0,1

at-least-once：ack = -1

**消费者-Broker**：
at-least-once
这种语义有可能会对数据重复处理
1: 设置enable.auto.commit为false，禁用自动提交offset
2: 消息处理完之后手动调用consumer.commitSync()提交offset

这种方式是在消费数据之后，手动调用函数consumer.commitSync()异步提交offset，有可能处理多次的场景是消费者的消息处理完并输出到结果库，但是offset还没提交，这个时候消费者挂掉了，再重启的时候会重新消费并处理消息，所以至少会处理一次

at-most-once
这种语义有可能会丢失数据
至多一次消费语义是kafka消费者的默认实现。配置这种消费者最简单的方式是
1: enable.auto.commit设置为true。
2: auto.commit.interval.ms设置为一个较低的时间范围。
由于上面的配置，此时kafka会有一个独立的线程负责按照指定间隔提交offset。

消费者的offset已经提交，但是消息还在处理中(还没有处理完)，这个时候程序挂了，导致数据没有被成 功处理，再重启的时候会从上次提交的offset处消费，导致上次没有被成功处理的消息就丢失了。

ExactlyOnlyOnce
这种语义可以保证数据只被消费处理一次。
1: 将enable.auto.commit设置为false，禁用自动提交offset
2: 使用consumer.seek(topicPartition，offset)来指定offset
3: 在处理消息的时候，要同时保存住每个消息的offset。

以原子事务的方式保存offset和处理的消息结 果，这个时候相当于自己保存offset信息了，把offset和具体的数据绑定到一块，数据真正处理成功的时 候才会保存offset信息

这样就可以保证数据仅被处理一次了。

### 11. Kafka创建Topic时如何将分区放置到不同的Broker中

- 副本因子不能大于 Broker 的个数；
- 第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；
- 其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；
- 剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的

### 12. 谈一谈 Kafka 的再均衡(rebalance)

在Kafka中，当有新消费者加入或者订阅的topic数发生变化时，会触发Rebalance(再均衡：在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者)机制，Rebalance顾名思义就是重新均衡消费者消费。Rebalance的过程如下：

①所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。

②leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。所以对于Rebalance来说，Coordinator起着至关重要的作用。

### 13. Kafka在搭建的时候要配置什么参数？

1、broker.id：broker标识符，默认是0。

2、port：端口，如果使用配置样本来启动Kafka，会默认监听9092端口。

3、zookeeper.connect：用于保存broker元数据的ZooKeeper地址。该配置参数是用逗号分隔的一组hostname:port/path列表，每一部分含义如下：

（1）hostname是ZooKeeper服务器的机器名或IP地址；

（2）port是Zookeeper的客户端连接端口；

（3）/path是可选的Zookeeper路径，作为Kafka集群的chroot环境。如果不指定，默认使用根路径。

4、log.dirs：存放日志片段的目录。

5、num.recovery.threads.per.data.dir：线程池个数。

6、auto.create.topics.enable：是否自动创建主题。

### 14. SparkStreaming对接kafka的两种方式

1. ### receiver方式

	1、receiver不停地从kafkaq拉取数据，n秒钟（程序设置的）拉取产生一批数据
	2、这种方式偏移量zookeeper帮我们管理，灵活性差

这种方式有缺点：
    receiver从Kafka中获取的数据都存储在Spark Executor的内存中，某个时间段内拉去的数据可能会大于某台机器executor分配的内存数量，部分数据会溢出丢失。
    针对这一问题，1.2版本之后提供记log方式（Streaming的预写日志机制）(Write Ahead Log，WAL)。该机制会将从kafka中读取的数据先保存到hdfs或者S3上，然后再去消费数据，WAL是为了防止数据的丢失，可以对数据进行恢复。所以，即使底层节点出现了失败，也可以使用预写日志中的数据进行恢复。
使用时的注意事项：
    1）Kafka中topic的partition与Spark中RDD的partition是没有关系的，因此，在KafkaUtils.createStream()中，提高partition的数量，只会增加Receiver的数量，也就是读取Kafka中topic partition的线程数量，不会增加Spark处理数据的并行度。
    2）可以创建多个Kafka输入DStream，使用不同的consumer group和topic，来通过多个receiver并行接收数据。
    3）如果基于容错的文件系统，比如HDFS，启用了预写日志机制，接收到的数据都会被复制一份到预写日志中。因此，在KafkaUtils.createStream()中，设置的持久化级别是StorageLevel.MEMORY_AND_DISK_SER。

2. direct方式

这种方式会周期性地查询Kafka，获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。这种方式的偏移量可以由我们开发人员管理，这样的话，它的灵活性很好，并且可以保证数据的安全性，而且不用担心数据量过大，因为他有预处理机制，进行提前处理，然后批次提交任务。

这种方式有如下的优点：
1)简化并行读取
如果要读取多个partition，不需要创建多个输入DStream，然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在Kafka partition和RDD partition之间，有一个一对一的映射关系。

2）高性能
如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有。

而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。

3）一次且仅一次的事务机制
基于receiver的方式，是使用Kafka的高阶API来在ZooKeeper中保存消费过的offset的。这是消费Kafka数据的传统方式。这种方式配合着WAL机制可以保证数据零丢失的高可靠性，但是却无法保证数据被处理一次且仅一次，可能会处理两次。
基于direct的方式，使用kafka的简单api，Spark Streaming自己就负责追踪消费的offset，并保存在checkpoint中。Spark自己一定是同步的，因此可以保证数据是消费一次且仅消费一次。

### 15. Zookeeper在Kafka中的应用

1）Controller选举

Kafka集群中会有一个Broker会被选举为Controller，对zookeeper进行监听，负责管理**broker的上下线**，所有**topic的分区副本分配**和**leader选举工作**。	

2）配置管理

Topic的配置之所以可以动态更新就是基于zookeeper做了一个动态全局配置管理。

3）负载均衡

基于zookeeper的消费者，实现了该特性，动态感知分区变动，将负载使用到既定分配策略分不到的消费者上。

4）分布式通知

如分区增加、Broker下线、topic变动等；

5）集群管理和master选举

可以通过命令行，对kafka集群上的topic partition分布，进行迁移管理，也可以对partition leader选举进行干预。

### 16. Kafka如何防止脑裂

kafka中只有一个控制器controller 负责分区的leader选举，同步broker的新增或删除消息，但有时由于网络问题，可能同时有两个broker认为自己是controller，这时候其他的broker就会发生脑裂，不知道该听从谁的。

每当新的controller产生的时候就会在zk中生成一个全新的、数值更大的controller epoch的标识，并同步给其他的broker进行保存，这样当第二个controller发送指令时，其他的broker就会自动忽略。

## 六、数仓面试题

### 1. 数仓的定义

数据仓库(Data Warehouse)的目的是构建面向分析的集成化数据环境，为企业提供决策支持。它出于分析性报告和决策支持的目的而创建。数据仓库本身并不生产任何数据，也不消费任何数据，数据全部来源于外部，并且开放给外部应用。

### 2. 数据仓库分层(层级划分)，每层做什么?分层的好处?分层的依据？

数仓的分层多种多样，按照数据流入流出的顺序，大致可分为：**源数据层、数据仓库层、数据应用层**。其中数据仓库层又分为DWD(detail)(明细数据层)和DWS(sum)(数据汇总层)。

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202207291128347.webp" alt="img" style="zoom:67%;" />

- 减少重复开发，在数据开发的过程中可以产生中间层，将公共逻辑下沉，减少重复计算；

- 清晰数据结构，每个分层分工明确，方便开发人员理解；

- 方便定位问题，通过分层了解数据血缘关系，在出问题的时候通过回溯定位问题；

- 简单化复杂问题，和分治法思想类似，分而治之，将复杂的问题简单化，还能解耦

### 3. 数仓建模的思路、流程和常用模型

建模流程：业务建模->概念建模 -> 逻辑建模 -> 物理建模

- **业务建模**：与业务部门充分沟通，理清部门关系，熟悉部门指标需求并可提供哪些数据。

- **概念建模**：将业务模型抽象化，分组合并类似概念，抽出实体和实体之间的关系，理清各概念实体之间的关系。（画局部ER图，最后综合画出整体ER图）

- **逻辑建模**：概念模型实体化，也就是表设计，这里主要考虑事实表的字段和业务主键，如果是维度表就考虑维度属性。在这里要确定数据的粒度，如果多个指标都要用到一个字段，则取粒度最小的指标。

- **物理建模**：综合实现大数据平台、采集平台、etl工具、数仓组件、性能要求、管理要求等多方面因素，设计出具体的项目代码。

建模思路：

- **自上而下**：Bill Inmon推崇“自上而下”，即企业建立唯一的数据中心，即数仓。数据是经过整合、清洗、标准且能够提供统一的视图。要建立这样的数仓，则需要从整个企业环境入手，分析其中的概念，应该有什么样的数据，而不是它需要支持哪些应用。
- **自下而上**：Ralph Kimball推崇“自下而上”，他认为建设数仓应该按照实际的应用需求，加载需要的数据，不需要的数据则不加载到数仓中。这种方式建设周期短，客户很快可以看到结果。（针对客户需求）

### 4. 维度建模和范式建模区别

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/1000" alt="img" style="zoom: 67%;" />

### 5. 维度表和事实表的区别

事实表：事实表的实质就是通过各种维度和一些指标值得组合来确定一个事实的，比如通过时间维度，地域组织维度，指标值可以去确定在某时某地的一些维度表的数据和指标值交汇而得到的。

维度表：维度表可以看成是用户用来分析一个事实的窗口，它里面的数据应该是对事实的各个方面描述，比如时间维度表，它里面的数据就是一些日，周，月，季，年，日期等数据维度表只能是维度表的一个分析角度。

### 6. 什么是ER模型

实体关系（ER）模型的目标是捕获现实世界的数据需求，并以简单、易理解的方式表现出来。ER模型可用于项目组内部交流或用于与用户讨论系统数据需求。

基本的ER模型包含三类元素：实体、关系、属性

### 7. OLAP和OLTP解释三范式，举例

1NF：每一列都是不可分割的原子数据项。

2NF：在1NF的基础上消除部分依赖，非关键字段不会部份依赖于候选码。比如（学号，课程）->成绩，学分->课程，所以学分部份依赖于候选码(学号，课程)的课程，不满足2NF

3NF：在2NF的基础上消除了传递依赖。比如 学号->学院地点， 学院地点->学院，存在传递依赖，不满足3NF。

### 8. 维度设计过程，事实设计过程

**维度设计过程**

1. 选择维度

在建设维度表中，要保证其在数仓中的唯一性，也就是说只允许有一个商品维表。

2. 确定维度主来源表

在此处一般指的就是ODS层（与业务系统表结构一样）的商品表，如s_items_info，此表就是维度的主来源表。

3. 确定相关维表

数据仓库的设计遵循数据的高度整合原则。在确定主来源表后，还需要根据实际需求，扩展商品的相关信息如：类目、所属卖家、所属店铺等

4. 确定维度属性

在维度主来源表+相关维表的基础字段上，创建或补充维度属性：

- 尽可能地生成新的维度属性
- 尽可能给出一些包含**文字描述**的属性，这些属性不应该只有编码，更应该是真正的**文字**。如一级类目ID，一级类目名称
- 某些特殊的**度量（数字）有可能也能作为维度属性**。如商品单价，既在观察商品价格段时可以作为维度，也可以在求平均商品价格时作为事实。（区分数值型字段是维度还是度量的方法之一，就是看字段内容枚举值的多寡，多很可能是度量；少很可能是维度，但不绝对）
- 尽量沉淀出**常用、公用**的字段。如商品状态，需要通过上架时间判断

**事实表设计过程**

1. 选择业务过程

比如淘宝交易订单有四个重要过程，创建订单、买家付款、卖家发货、买家确认收货，即下单、支付、发货和成功完结四个业务过程。这四个业务过程不仅是交易过程中的重要时间节点，同时也是下游统计分析的重点，因此淘宝交易事务事实表着重从这个四个业务过程进行展开。

2. 确定粒度

业务过程选定以后，就要针对每个业务过程确定一个粒度，即确定事务事实表每一行所表达的细节层次。

3. 确定维度

对于选定的业务过程并且确定粒度后，就可以确定维度信息。淘宝交易事务事实表在设计过程中，按照经常用于统计分析的场景，确定维度包含：买家维度、卖家维度、商品维度、商品类目维度、发货地区维度、收货地区维度、父订单维度以及杂项维度。由于订单的属性较多，比如订单的业务类型、是否无线交易、订单属性attributes等等，这些使用较多却又无法归属到上述买卖家或商品维度中则新建一个杂项维度进行存放。

4. 确定事实

作为过程度量的核心，**事实表应该包含与其描述过程有关的所有事实**。以淘宝交易事务事实表为例，选定三个业务过程——下单、支付和成功完结，不同的业务过程拥有不同的事实。比如下单业务过程中，需要包含下单金额、下单数量、下单分摊金额，支付业务过程中，包含支付金额、分摊邮费、折扣金额、红包金额、积分金额，完结业务过程中包含确认收货金额等，由于粒度是子订单的，所以对于一些父订单上的金额需要平摊到子订单上，比如父订单邮费、父订单折扣等，具体分摊算法将在父子事实处理方式一节介绍。

根据Kimball维度建模理论，经过以上四步，淘宝交易事务事实表已初见成型，可以满足下游分析统计需要，然而阿里巴巴数据仓库在建模时，基于以上四个过程增加了一步——退化维度，这个过程在Kimball维度建模中也有所提及，但阿里数仓基于效率和资源考虑将常用维度全部退化到事实表中，使下游分析使用模型更加方便。

5. 冗余维度

第三步确定维度时，包含了买卖家维度、商品维度、类目维度、收发货维度等等，Kimball维度建模建议在事实表中只保存这些维度表的外键，而淘宝交易事务事实表在Kimball维度建模基础之上做了进一步的优化，将买卖家的星级、标签、店铺名称、商品类型、商品特征、商品属性、类目层级等等维度属性都冗余到事实表中，提高对事实表过滤查询、统计聚合的效率。

### 9. 维度设计中有整合和拆分，有哪些方法，并详细说明

**维度整合**

1. 垂直整合

不同的数据源包含相同数据集，如，A业务会员表，B业务会员表，都属于会员信息应该尽量聚合在会员维度，丰富维度属性；

2. 水平整合

- 判断数据集是否交叉，是则去重
- 判断自然键是否冲突，是则加工成复合主键，否则直接用数据集的主键作为整合表的主键
- 在物理实现时将来源字段作为分区字段

**维度拆分**

1. 水平拆分

① 维度属性随类型变化会发生很大变化时，没有必要把所有属性整合在一张表中，而用主维度保存公共数据，保证核心维度的稳定性，同时建立多个子维度，保证扩展性

② 两个业务相关性低，整合在一起会对模型的稳定性和易用性产生影响

2. 垂直拆分

考虑到某些维度属性的来源表产出时间早，某些产出晚；某些属性位数使用频率高，某些频率低；某些属性稳定性高，某些经常变化。把产出时间早、使用频率高、稳定性高的属性放在主维度中，把产出时间晚、使用频率低、经常变化的属性放在子维度中

### 10. 事实表设计分几种，每一种都是如何在业务中使用

1. 事务事实表

```
事务事实表记录事务层面的事实，保存最为原子的数据，其数据在事务发生后发生，粒度为每一行数据。其一旦提交不能修改，增量更新。

事实表一般围绕着度量来建立，当度量产生的时候，事实记录就生成了。度量可以是销售数量、交易流水值、月末节余等数值。一般会根据数据度量以及提前规定好的一致性维度来进行统计等工作。
事务的数字度量分为三种：
1）可加事实
可加事实指的是该度量可以按照和事实表关联的任一维度进行汇总。比如商品的单价，可以按照品类维度进行汇总，按照店铺维度进行汇总等等
2）半可加事实
指的就是该度量在某些维度下不可进行汇总，或者说汇总起来没有意义，比如说价差额，价差额在时间维度下的汇总就没有意义。
3）不可加事实
指的是该度量在所有与该事实表关联的维度下都不可进行汇总，比如说比率型数据
```

2. 周期快照事实表

```
周期快照表以具有规律性、可预见时间的记录事实，它统计的是间隔周期内的度量统计，如历史至今、自然年至今、季度至今等等，其更新方式同事务事实表，采用增量更新。
周期快照事实表粒度是每个时间段一条记录，通常比事务事实表的粒度要粗，是在事务事实表之上建立的聚集表，维度比事务事实表要小，但记录的事实比事务事实表更多，事务事实表是稀疏表，周期快照表是稠密表。   

1）什么是稀疏表，什么是稠密表？

　　稀疏表：当天只有发生了操作才会有记录

　　稠密表：当天没有操作也会有记录，便于下游使用
事务事实表是 稀疏的，只有当天发生的业务过程，事实表才会记录该业务过程的事 实， 如下单、支付等;而快照事实表是稠密的，无论当天是否有业务过程发 生，都会记录一行，比如针对卖家的历史至今的下单和支付金额，无论 当天卖家是否有下单支付事实，都会给该卖家记录一行
就比如用户周一下单3单，周二没有下单，但系统仍在周二分区里记录该周下单3单。

```

3. 累计快照事实表

```
累计快照事实表与周期快照事实表比较相似，都是存储事务数据的快照，但后者积累确定周期的数据，而积累积累不确定周期的数据，其可能覆盖一个完整的事务或产品的生命周期，通常有多个日期字段，记录生命周期的关键时间点，比如订单记录快照事实表有付款日期，发货日期和收货日期时间点。
周期快照事实表记录重复的可预测到的时间间隔事实，例如账号月余结事实表，而记录快照事实表适合较短周期，有明确开始时间和结束状态时间，中间记录每个步骤的执行时间，使得分析人员对整体过程有所把握。
```

### 11. 单事务事实表、多事务事实表区别与作用

**单事务事实表**
即针对每个业务过程设计一个事实表（如下单、支付、发货分别建立事实表）。优点是便于对每个业务过程进行独立的分析。

**多事务事实表**
不同业务过程使用不同的事实字段进行存放；或不同业务过程使用同一个事实字段进行存放，但增加一个业务过程标签。可以针对每一个业务过程打一个标签，比如is_td_finish这种，以解决不同业务过程跨天的问题。

**二者区别**

```
1、分析不同业务过程的相似性。比如下单、支付和成功完结都是订单处理过程中的一环，因此适合放到同一个事物事实表中。
2、不同业务过程的维度和粒度是否相同。比如支付和发货有不同的粒度，因此不适合放到同一个事实表中。
3、如果使用多事实事务表，会导致事实表零值或空值字段过多，则更适合采用单事实事务表。
4、何者更便于下游用户使用
5、计算存储成本
```

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/v2-967e2e01071fdf68a219221c72572a20_720w.jpg" alt="img"  />

### 12. 说下一致性维度、一致性事实、总线矩阵

**总线矩阵**

 多维体系结构主要包括后台（Back Room）和前台（Front Room）两部分。后台也称为数据准备区（Staging Area），是MD架构的最为核心的部件。在后台，是一致性维度的产生、保存和分发的场所。同时，代理键也在后台产生。 前台是MD架构对外的接口，包括两种主要的数据集市，一种是**原子数据集市**，另一种是**聚集数据集市**。原子数据集市保存着最低粒度的细节数据，数据以星型结构来进行数据存储。聚集数据集市的粒度通常比原子数据集市要高，和原子数据集市一样，聚集数据集市也是以星型结构来进行数据存储。前台还包括像查询管理、活动监控等为了提供数据仓库的性能和质量的服务。 在多维体系结构中，所有的这些基于星型机构来建立的数据集市可以在物理上存在于一个数据库实例中，也可以分散在不同的机器上，而所有这些数据集市的集合组成的分布式的数据仓库。

 **一致性维度** 

在多维体系结构中，没有物理上的数据仓库，由物理上的数据集市组合成逻辑上的数据仓库。而且数据集市的建立是可以逐步完成的，最终组合在一起，成为一个数据仓库。如果分步建立数据集市的过程出现了问题，数据集市就会变成孤立的集市，不能组合成数据仓库，而一致性维度的提出正式为了解决这个问题。 一致性维度的范围是总线架构中的维度，即可能会在多个数据集市中都存在的维度，这个范围的选取需要架构师来决定。一致性维度的内容和普通维度并没有本质上区别，都是经过数据清洗和整合后的结果。 一致性维度建立的地点是多维体系结构的后台（Back Room），即数据准备区。在多维体系结构的数据仓库项目组内需要有专门的维度设计师，他的职责就是**建立维度和维护维度的一致性。在后台建立好的维度同步复制到各个数据集市。这样所有数据集市的这部分维度都是完全相同的**。

**一致性事实**

 一致性事实和一致性维度有些不同，一致性维度是由专人维护在后台（Back Room），发生修改时同步复制到每个数据集市，而事实表一般不会在多个数据集市间复制。需要查询多个数据集市中的事实时，一般通过交叉探查（drill across）来实现。 为了能在多个数据集市间进行交叉探查，一致性事实主要需要保证两点。第一个是KPI的定义及计算方法要一致，第二个是事实的单位要一致性。如果业务要求或事实上就不能保持一致的话，建议不同单位的事实分开建立字段保存。

### 13. 从ODS层到DW层的ETL，做了哪些工作?

1. ODS -> DWD：对ODS层进行数据清洗，去除空值、去脏数据、维度退化、脱敏等；此层会使用明细宽表，复用关联计算，减少数据扫描。
2. DWD -> DWS：以DWD为基础进行汇总，形成大宽表，例如用户行为宽表、注册宽表等。DWS层的宽表字段，是站在不同维度的视角去看事实表，重点关注事实表的度量值，通过与之关联的事实表，获得不同的事实表的度量值。
3. DWS -> ADS：分别对设备主题、会员主题、商品主题和营销主题进行指标分析，其中营销主题是用户主题和商品主题的跨主题分析案例。存储计算具体的指标，并且相比于主题层有更明显的应用场景，比如7日内活约用户数等。

### 14. 数据仓库与(传统)数据库的区别?

- 数据仓库与传统数据库的区别实际上是OLTP(On-line Transaction Processing)和OLAP(On-line Analytical Processing)的区别，前者侧重于事务，例如对于交易事件的数据记录；而后者则侧重于分析，面向主题进行设计，例如出报表等。
- 数据库是面向事务的设计，数据仓库是面向主题设计的。
- **数据库**设计是尽量避免冗余，一般针对某一业务应用进行设计；比如一张简单的User表，记录用户名、密码等简单数据即可，符合业务应用，但是不符合分析；**数据仓库**在设计是有意引入冗余，依照分析需求，分析维度、分析指标进行设计。

- 虽然传统的OLTP(例如MySQL、Oracle)型数据库也可以进行数据的分析，但随着数据量级的增加，很多数据存储于分布式存储系统中，想要跨集群、关联多种数据，OLTP就显得无能为力。
- 数据仓库，是在数据库已经大量存在的情况下，为了进一步挖掘数据资源、为了决策需要而产生的，它决不是所谓的“大型数据库”。

### 15. 数据质量是怎么保证的，有哪些方法保证

**数据质量**：指我们数据加工、转换、计算等整个流程中的数据正确性，主要体现在**ODS层和ADS层**急需要数据质量，ODS主要判断ODS中的数据和业务库中的数据是否一致(条数)，ADS层主要是看最终指标是否正确，也即入口和出口一定把质量监控好。
1、大公司就可以说是公司自研的数据质量系统来保障数据质量，保证ODS同步数据是否多少、可以配置ODS层数据量为上游数据的百分比、可以**配置告警**。如：业务库订单表今天3000万条，但是采集到ODS层2000万条，配置告警规则为业务库orders/ods层orders=100%，这个时候肯定就要触发告警，因为订单涉及到钱，一条数据都不能丢。行为日志可以丢一些，自行根据需求设置即可。
2、小公司，就是将1步骤中的实现过程自己实现，比如第一个版本使用Shell脚本自己实现ODS层和ADS层数据质量监控的；第二版本自己写的web项目来对数据质量监控，主要实现数据条数、同环比指标的一些监控。或者使用开源的框架：Griffin或DolphinScheduler 3.0就有数据质量功能了。

### 16. 怎么衡量数仓的质量，有哪些指标

从技术方面，数据仓库应该具有所有技术项目都应该满足的成本、质量、效率要求，同时要满足安全等要求。

```
1. 质量
数据仓库应该提供给准确的数据，应该不会有人认为数仓应该提供未经验证的数据，进而导致做出错误的业务决策。
可以用下面几个指标来衡量数据仓库的质量：
超时任务数：运行时间超过某个阀值的任务数（对于实时数仓可以是日志处理延迟）
失败任务数：运行失败的任务数（对于实时数仓可以是日志处理失败）
ADS模型热度：ADS层模型被使用的次数（反应统一口径后的模型表的利用情况）
ODS模型热度：ODS层模型被使用的次数（反应未统一口径的原始日志被利用情况）
DQC成功率：满足DQC监控要求的指标占比
```

```
2. 效率
数据仓库应该尽可能快的提供数据，满足日益变快的商业竞争需要。
可以用下面几个指标来衡量数据仓库的效率：
SLA成功率：满足SLA要求的任务占比
查询时间：查询数据花费的时间
```

```
3. 成本
数据仓库建设需要消耗大量的服务器等开发资源，尤其是互联网公司的数据量一般都比较大，集群成本负担比较重。
可以用下面几个指标来衡量数据仓库的成本：
任务数：数仓中计算任务的总数
存储量：数仓中模型存储数据量大小
模型依赖度：ODS、DW、ADS层模型的下游依赖数（反应模型的冗余情况，DW层应该被广泛共用，好的数仓应该减少过多冗余）
```

```
4. 安全
数据仓库中存储着大量的数据，也有非常重要的竞争信息，如果随意泄露机密数据可能造成不利的商业竞争影响。数据安全机制包括数据分级、权限审批、审计日志等方式，对于核心机密数据可以考虑加密存储，限制访问等方式。
可以用下面几个指标来衡量数据仓库的安全：
密级覆盖度：拥有密级设置的模型占比（财务、用户信息应该是高密，高密表占比合理）
高密表热度：高密模型被访问的次数
```

从业务方面，数据仓库应该支撑业务建设，覆盖尽可能多的业务场景，需要数据时能够及时取到，能满足业务数据化需求，至于数据业务化在绝大部分公司中比较难以实现，支撑业务建设需要考虑以下几个方面：

```
1. 覆盖
数据仓库应该尽可能多的覆盖业务场景，当需要使用数据支持业务决策时能够快速的提供准确的数据。为了达到覆盖尽可能多的场景，就要求数仓开发人员要时刻跟进业务变化，主动挖掘和建设数据模型。如果是数据驱动型组织，产品运营同学的数据意识较好，会主动设计数据指标体系，减轻数仓同学的开发压力。
可以用下面几个指标来衡量数据仓库的业务覆盖：
数据需求处理时长：数据需求平均开发时长（数据场景覆盖丰富，应该较快完成数据需求）
```

```
2. 易用
数据仓库提供的数据对于业务应该是易用的，如果一个数据系统非常难用，自然不会有人用，进而产生不了价值，如果一个数据系统好用，用户会自然传播推荐其他人来用。
可以用下面几个指标来衡量数据仓库的易用性：
下游数据系统数：数仓输出的数据对接了多少个数据系统（评估有多少数据系统的数据是不是来自于数仓，不同来源的数据容易出现不一致情况）
数据产品PV、UV、使用时长：数据产品访问用户数、访问次数、使用时长
数据用户占比：使用数据产品的人占公司总员工人数的比
```

### 17. 增量表、全量表和拉链表

#  场景题

## 一、大文件处理

问：假如有一个1G大小的文件，文件里每一行是一个词，每个词的大小不超过16byte，要求返回出现频率最高的100个词。内存大小限制10M。

答：由于内存限制，我们无法将大文件的所有词一次性读到内存中，因此可以采用分治的策略，保证每个文件的大小小于10M，进而直接将单个小文件读到内存中进行处理。

第一步，遍历大文件，对遍历到的每个词x，执行hash(x)%500，将结果为i的词存放到文件f(i)中，遍历结束后可以得到500个小文件；之所以使用500个小文件，是因为原文件大小为1G，1G/500=2M，每个小文件的大小为2M左右，基本不会超过内存大小10M的限制。

第二步，接着统计每个小文件中出现频数最高的100个词，可以使用HashMap来实现，其中key为词，value为词频，对于遍历到的词，如果在map中存在，则执行map.put(x,map.get(x)+1)，将该词出现的次数+1。

第三步，在第二步中找出了每个文件出现频率最高的100个词之后，通过维护一个小顶堆来找出所有小文件中出现频率最高的100个词。具体方法是：遍历第一个文件，把第一个文件中出现频率最高的100个词构建成一个小顶堆，如果第一个文件中的词的个数小于100，则可以继续遍历第二个文件，知道构建好有100个结点的小顶堆为止。继续遍历其他小文件，如果遍历到的词的出现次数大于堆顶上词的出现次数，可以用新遍历到的词替换堆顶的词，然后重新调整这个堆为小顶堆。

总结一下，采用分治思想，进行哈希取余，使用HashMap统计每个小文件单词出现的次数；维护一个小顶堆，遍历步骤2中的小文件，找出出现频率top100的单词。

# 数据结构和算法

## 1. 排序算法的比较

 ![在这里插入图片描述](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20210225144127497.png)
