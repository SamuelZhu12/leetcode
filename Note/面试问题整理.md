# JAVA

##  1. Static和Final的区别？

static
static是静态的意思，也是全局的意思。static定义的东西，属于全局，与类相关，不与具体实例相关，是类实例之间共享的。

1. 被static修饰的变量属于类变量，可以通过类名.变量名直接引用，而不需要new出一个对象来

2. 被static修饰的方法属于类方法，可以通过类名.方法名直接引用，而不需要new出一个对象来

static与非static的区别：

在内存中存放的位置不同：所有static修饰的属性和方法都放在内存的方法区（内存的方法区相当于常驻内存，如果一个方法或者变量声明为static，可以节约内存，不必要为每个对象实例化的时候分配内存）里，而非静态的都堆放在堆内存中

生命周期不同：静态在类消失后被销毁，非静态在对象销毁后销毁。

final
final关键字有三个东西可以修饰，修饰非抽象类，修饰非抽象方法，修饰引用。

在类的声明中使用final:

使用了final的类不能再派生子类，就是不可以被继承，简称为断子绝孙类。类中的所有方法都不能被重写。有一些java的面试题问，String可不可以被继承，答案是不可以。因为java.lang.String是一个final类。这可以保证String对象方法的调用确实运行的是String类的方法，而不是经其子类重写后的方法。

在方法的声明中使用final:

被定义为final的方法不能被重写，这个方法成为最终方法，但是该方法仍然可以被继承。如果定义类为final，是所有的方法都不能被重写。而我们只需要类中的几个方法不可以被重写，就在方法前面加上final，而且被定义为final的方法执行效率高。final不能修饰构造方法。

在修饰引用中使用final：

如果引用为基本数据类型，这样变量就是常量了，在程序中这样的变量不可以被修改，修改编译器会报错，而且执行效率比普通的变量要高。final的变量如果没有赋予初值的话，其他方法就必须给他赋值，但只能赋值一次。

如果引用为引用数据类型，比如对象，数组，则该对象、数组本身可以修改，但是指向该对象或数组的地址的引用不能修改。

如果引用的是类的成员变量，则必须当场赋值，否则编译会报错。

static和final一起用：final与static final的区别是：final在 e一个对象类唯一，static final在多个对象中都唯一；一个既是static又是final的域只占据一段不能改变的存储空间，只有一份。

## 2. 为什么调用 start() 方法时会执行 run() 方法，而不能直接调用 run() 方法？

new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

总结： 调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。

## 3.sleep() 方法和 wait() 方法区别和共同点?
两者最主要的区别在于：sleep() 方法没有释放锁，而 wait() 方法释放了锁 。

两者都可以暂停线程的执行。

wait() 通常被用于线程间交互/通信，sleep()通常被用于暂停执行。

wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。sleep()方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。

# 大数据组件

## 1. 性能调优

### 1.1 如何提高Hadoop、Hive及Spark的并行度？

**Hadoop**：Hadoop的并行度取决于MapTask和ReduceTask的数量，而MapTask的数量取决于File的切片Split数量。而Split的逻辑及实现方法由FileInputFormat实现类的getSplits()方法完成。切片大小的参数取决于`mapreduce.input.fileinputformat.split.minsize`和` mapreduce.input.fileinputformat.split.maxsize` 

**Spark**：一个Spark作业是一个Application，而Application会因为行动算子而被划分为多个Jobs，一个Jobs被划分为多个task，task的数量代表了spark作业在各个阶段的并行度。至少将task的数量设置成与Spark Application的总cpu core数量相同，官方推荐设置成Application总cpu core数量的2~3倍，比如150个cpu core，设置task数量为300～500，这样的话一个task运行完以后另外的task会补过来，cpu core就不会空闲了。

提高并行度方法：

1. 调整分区数量参数`spark.default.parallelism`，该参数默认是没有值的，设置后在shuffle的过程起作用；
2. 如果读取的数据在HDFS上，可以增加block数量，默认情况下split跟block是一对一的，而split与block数量一对一，split与RDD中的partition对应，增加block数量也就增加了并行度；
3. RDD.repartition，给RDD重新设置partition的数量
4. reduceByKey算子重新指定partition的数量

5. spark.sql.shuffle.partitions sql中shuffle过程partitions的数量

**Hive**：

Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。

通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。

set hive.exec.parallel=true;              //打开任务并行执行
set hive.exec.parallel.thread.number=16;  //同一个sql允许最大并行度，默认为8。

### 1.2 Spark数据倾斜怎么解决？

**数据倾斜的原理很简单**：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。

因此出现数据倾斜的时候，Spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。

下图就是一个很清晰的例子：hello这个key，在三个节点上对应了总共7条数据，这些数据都会被拉取到同一个task中进行处理；而world和you这两个key分别才对应1条数据，所以另外两个task只要分别处理1条数据即可。此时第一个task的运行时间可能是另外两个task的7倍，而整个stage的运行速度也由运行最慢的那个task所决定。

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241613258.png" alt="img" style="zoom:80%;" />

- **解决方案一**：使用 Hive ETL预处理数据
- **解决方案二**：过滤少数导致倾斜的key
- **解决方案三**：提高shuffle操作的并行度
- **解决方案四**：两阶段聚合（局部聚合+全局聚合）
- **解决方案五**：将reduce join转为map join
- **解决方案六**：采样倾斜key并分拆join操作
- **解决方案七**：使用随机前缀和扩容RDD进行join
- **解决方案八**：多种方案组合使用

- 解决方案一：使用 Hive ETL 预处理数据

**方案适用场景**：导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。

**方案实现思路**：此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。

**方案实现原理**：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。

**方案优点**：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。

**方案缺点**：治标不治本，Hive ETL中还是会发生数据倾斜。

**方案实践经验**：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。

**项目实践经验**：在美团·点评的交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。

- 解决方案二：过滤少数导致倾斜的key

**方案适用场景**：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。

**方案实现思路**：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。

**方案实现原理**：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。

**方案优点**：实现简单，而且效果也很好，可以完全规避掉数据倾斜。

**方案缺点**：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。

**方案实践经验**：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。

- 解决方案三：提高shuffle操作的并行度

**方案适用场景**：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。

**方案实现思路**：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。

**方案实现原理**：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。

**方案优点**：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。

**方案缺点**：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。

**方案实践经验**：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。

- 解决方案四：两阶段聚合（局部聚合+全局聚合）

**方案适用场景**：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。

**方案实现思路**：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。

**方案实现原理**：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。

**方案优点**：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。

**方案缺点**：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。

![img](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241623936.png)

```java
// 第一步，给RDD中的每个key都打上一个随机前缀。
JavaPairRDD<String, Long> randomPrefixRdd = rdd.mapToPair(
        new PairFunction<Tuple2<Long,Long>, String, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, Long> call(Tuple2<Long, Long> tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(10);
                return new Tuple2<String, Long>(prefix + "_" + tuple._1, tuple._2);
            }
        });
 
// 第二步，对打上随机前缀的key进行局部聚合。
JavaPairRDD<String, Long> localAggrRdd = randomPrefixRdd.reduceByKey(
        new Function2<Long, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });
 
// 第三步，去除RDD中每个key的随机前缀。
JavaPairRDD<Long, Long> removedRandomPrefixRdd = localAggrRdd.mapToPair(
        new PairFunction<Tuple2<String,Long>, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<Long, Long> call(Tuple2<String, Long> tuple)
                    throws Exception {
                long originalKey = Long.valueOf(tuple._1.split("_")[1]);
                return new Tuple2<Long, Long>(originalKey, tuple._2);
            }
        });
 
// 第四步，对去除了随机前缀的RDD进行全局聚合。
JavaPairRDD<Long, Long> globalAggrRdd = removedRandomPrefixRdd.reduceByKey(
        new Function2<Long, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });
```

解决方案五：将reduce join转为map join

**方案适用场景**：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。

**方案实现思路**：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。

**方案实现原理**：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。**方案优点**：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。**方案缺点**：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。

![img](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241624829.png)

```java

// 首先将数据量比较小的RDD的数据，collect到Driver中来。
List<Tuple2<Long, Row>> rdd1Data = rdd1.collect()
// 然后使用Spark的广播功能，将小RDD的数据转换成广播变量，这样每个Executor就只有一份RDD的数据。
// 可以尽可能节省内存空间，并且减少网络传输性能开销。
final Broadcast<List<Tuple2<Long, Row>>> rdd1DataBroadcast = sc.broadcast(rdd1Data);
 
// 对另外一个RDD执行map类操作，而不再是join类操作。
JavaPairRDD<String, Tuple2<String, Row>> joinedRdd = rdd2.mapToPair(
        new PairFunction<Tuple2<Long,String>, String, Tuple2<String, Row>>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, Tuple2<String, Row>> call(Tuple2<Long, String> tuple)
                    throws Exception {
                // 在算子函数中，通过广播变量，获取到本地Executor中的rdd1数据。
                List<Tuple2<Long, Row>> rdd1Data = rdd1DataBroadcast.value();
                // 可以将rdd1的数据转换为一个Map，便于后面进行join操作。
                Map<Long, Row> rdd1DataMap = new HashMap<Long, Row>();
                for(Tuple2<Long, Row> data : rdd1Data) {
                    rdd1DataMap.put(data._1, data._2);
                }
                // 获取当前RDD数据的key以及value。
                String key = tuple._1;
                String value = tuple._2;
                // 从rdd1数据Map中，根据key获取到可以join到的数据。
                Row rdd1Value = rdd1DataMap.get(key);
                return new Tuple2<String, String>(key, new Tuple2<String, Row>(value, rdd1Value));
            }
        });
 
// 这里得提示一下。
// 上面的做法，仅仅适用于rdd1中的key没有重复，全部是唯一的场景。
// 如果rdd1中有多个相同的key，那么就得用flatMap类的操作，在进行join的时候不能用map，而是得遍历rdd1所有数据进行join。

```

- 解决方案六：采样倾斜key并分拆join操作

**方案适用场景**：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。

**方案实现思路**：

- 对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。
- 然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。
- 接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。
- 再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。
- 而另外两个普通的RDD就照常join即可。
- 最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。

**方案实现原理**：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。具体原理见下图。

**方案优点**：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。

**方案缺点**：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。

<img src="https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/typora/202208241626975.png" alt="img" style="zoom:67%;" />

```java
// 首先从包含了少数几个导致数据倾斜key的rdd1中，采样10%的样本数据。
JavaPairRDD<Long, String> sampledRDD = rdd1.sample(false, 0.1);
 
// 对样本数据RDD统计出每个key的出现次数，并按出现次数降序排序。
// 对降序排序后的数据，取出top 1或者top 100的数据，也就是key最多的前n个数据。
// 具体取出多少个数据量最多的key，由大家自己决定，我们这里就取1个作为示范。
JavaPairRDD<Long, Long> mappedSampledRDD = sampledRDD.mapToPair(
        new PairFunction<Tuple2<Long,String>, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<Long, Long> call(Tuple2<Long, String> tuple)
                    throws Exception {
                return new Tuple2<Long, Long>(tuple._1, 1L);
            }     
        });
JavaPairRDD<Long, Long> countedSampledRDD = mappedSampledRDD.reduceByKey(
        new Function2<Long, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });
JavaPairRDD<Long, Long> reversedSampledRDD = countedSampledRDD.mapToPair( 
        new PairFunction<Tuple2<Long,Long>, Long, Long>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<Long, Long> call(Tuple2<Long, Long> tuple)
                    throws Exception {
                return new Tuple2<Long, Long>(tuple._2, tuple._1);
            }
        });
final Long skewedUserid = reversedSampledRDD.sortByKey(false).take(1).get(0)._2;
 
// 从rdd1中分拆出导致数据倾斜的key，形成独立的RDD。
JavaPairRDD<Long, String> skewedRDD = rdd1.filter(
        new Function<Tuple2<Long,String>, Boolean>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2<Long, String> tuple) throws Exception {
                return tuple._1.equals(skewedUserid);
            }
        });
// 从rdd1中分拆出不导致数据倾斜的普通key，形成独立的RDD。
JavaPairRDD<Long, String> commonRDD = rdd1.filter(
        new Function<Tuple2<Long,String>, Boolean>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2<Long, String> tuple) throws Exception {
                return !tuple._1.equals(skewedUserid);
            } 
        });
 
// rdd2，就是那个所有key的分布相对较为均匀的rdd。
// 这里将rdd2中，前面获取到的key对应的数据，过滤出来，分拆成单独的rdd，并对rdd中的数据使用flatMap算子都扩容100倍。
// 对扩容的每条数据，都打上0～100的前缀。
JavaPairRDD<String, Row> skewedRdd2 = rdd2.filter(
         new Function<Tuple2<Long,Row>, Boolean>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2<Long, Row> tuple) throws Exception {
                return tuple._1.equals(skewedUserid);
            }
        }).flatMapToPair(new PairFlatMapFunction<Tuple2<Long,Row>, String, Row>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Iterable<Tuple2<String, Row>> call(
                    Tuple2<Long, Row> tuple) throws Exception {
                Random random = new Random();
                List<Tuple2<String, Row>> list = new ArrayList<Tuple2<String, Row>>();
                for(int i = 0; i < 100; i++) {
                    list.add(new Tuple2<String, Row>(i + "_" + tuple._1, tuple._2));
                }
                return list;
            }
 
        });
 
// 将rdd1中分拆出来的导致倾斜的key的独立rdd，每条数据都打上100以内的随机前缀。
// 然后将这个rdd1中分拆出来的独立rdd，与上面rdd2中分拆出来的独立rdd，进行join。
JavaPairRDD<Long, Tuple2<String, Row>> joinedRDD1 = skewedRDD.mapToPair(
        new PairFunction<Tuple2<Long,String>, String, String>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, String> call(Tuple2<Long, String> tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(100);
                return new Tuple2<String, String>(prefix + "_" + tuple._1, tuple._2);
            }
        })
        .join(skewedUserid2infoRDD)
        .mapToPair(new PairFunction<Tuple2<String,Tuple2<String,Row>>, Long, Tuple2<String, Row>>() {
                        private static final long serialVersionUID = 1L;
                        @Override
                        public Tuple2<Long, Tuple2<String, Row>> call(
                            Tuple2<String, Tuple2<String, Row>> tuple)
                            throws Exception {
                            long key = Long.valueOf(tuple._1.split("_")[1]);
                            return new Tuple2<Long, Tuple2<String, Row>>(key, tuple._2);
                        }
                    });
 
// 将rdd1中分拆出来的包含普通key的独立rdd，直接与rdd2进行join。
JavaPairRDD<Long, Tuple2<String, Row>> joinedRDD2 = commonRDD.join(rdd2);
 
// 将倾斜key join后的结果与普通key join后的结果，uinon起来。
// 就是最终的join结果。
JavaPairRDD<Long, Tuple2<String, Row>> joinedRDD = joinedRDD1.union(joinedRDD2);
```

解决方案七：使用随机前缀和扩容RDD进行join

**方案适用场景**：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。

**方案实现思路**：

- 该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。
- 然后将该RDD的每条数据都打上一个n以内的随机前缀。
- 同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条-数据都依次打上一个0~n的前缀。
- 最后将两个处理后的RDD进行join即可。

**方案实现原理**：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。

**方案优点**：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。

**方案缺点**：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。

**方案实践经验**：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。

```java
// 首先将其中一个key分布相对较为均匀的RDD膨胀100倍。
JavaPairRDD<String, Row> expandedRDD = rdd1.flatMapToPair(
        new PairFlatMapFunction<Tuple2<Long,Row>, String, Row>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Iterable<Tuple2<String, Row>> call(Tuple2<Long, Row> tuple)
                    throws Exception {
                List<Tuple2<String, Row>> list = new ArrayList<Tuple2<String, Row>>();
                for(int i = 0; i < 100; i++) {
                    list.add(new Tuple2<String, Row>(0 + "_" + tuple._1, tuple._2));
                }
                return list;
            }
        });
 
// 其次，将另一个有数据倾斜key的RDD，每条数据都打上100以内的随机前缀。
JavaPairRDD<String, String> mappedRDD = rdd2.mapToPair(
        new PairFunction<Tuple2<Long,String>, String, String>() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2<String, String> call(Tuple2<Long, String> tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(100);
                return new Tuple2<String, String>(prefix + "_" + tuple._1, tuple._2);
            }
        });
 
// 将两个处理后的RDD进行join即可。
JavaPairRDD<String, Tuple2<String, Row>> joinedRDD = mappedRDD.join(expandedRDD);
```

解决方案八：多种方案组合使用

在实践中发现，很多情况下，如果只是处理较为简单的数据倾斜场景，那么使用上述方案中的某一种基本就可以解决。但是如果要处理一个较为复杂的数据倾斜场景，那么可能需要将多种方案组合起来使用。比如说，我们针对出现了多个数据倾斜环节的Spark作业，可以先运用解决方案一和二，预处理一部分数据，并过滤一部分数据来缓解；其次可以对某些shuffle操作提升并行度，优化其性能；最后还可以针对不同的聚合或join操作，选择一种方案来优化其性能。大家需要对这些方案的思路和原理都透彻理解之后，在实践中根据各种不同的情况，灵活运用多种方案，来解决自己的数据倾斜问题。

## 2. HDFS文件块为什么设置成128M

1. 如果块设置过大，

   一方面，从磁盘传输数据的时间会明显大于寻址时间，导致程序在处理这块数据时，变得非常慢；

   另一方面，mapreduce中的map任务通常一次只处理一个块中的数据，如果块过大运行速度也会很慢。

2. 如果块设置过小，

   一方面存放大量小文件会占用NameNode中大量内存来存储元数据，而NameNode的内存是有限的，不可取；

   另一方面文件块过小，寻址时间增大，导致程序一直在找block的开始位置。

   ```
   1. HDFS中平均寻址时间大概为10ms；
   2. 经过前人的大量测试发现，寻址时间为传输时间的1%时，为最佳状态；
   所以最佳传输时间为10ms/0.01=1000ms=1s
   3. 目前磁盘的传输速率普遍为100MB/s；
   计算出最佳block大小：100MB/s x 1s = 100MB
   所以我们设定block大小为128MB。
   ```

## 3. HDFS写数据过程，写的过程中有哪些故障，分别会怎么处理?

1. 如果DN收到一半 DN挂了的处理流程：
  客户端每读取64K的数据，封装为一个packet，封装成功的packet，放入到一个队列中，这个队列称为dataQuene(待发送数据包)在发送时，先将dataQuene中的packet按顺序发送，发送后再放入到ackquene(正在发送的队列)。每个节点在收到packet后，向客户端发送ack确认消息！当所有DN都发送ack，客户端收到这些ack后，传输成功，ackquene删除掉这个packet。假如一个packet在发送后，在收到DN返回的ack确认消息时超时，传输中止，将此时所有DN中正在传输的packet剔除，ackquene中的packet会回滚到dataQuene。重新建立通道，剔除坏的DN节点，包括里面的所有信息。建立完成之后，继续传输！只要有一个DN节点收到了数据，DN上报NN已经收完此块，NN就认为当前块已经传输成功！NN会自动维护副本数！

2. 读取文件时DN挂了
  DataNode 挂了只需要失败转移到其他副本所在的 DataNode 继续读取
3. 读取到的文件数据损坏
读取到的文件数据块若校验失败可认定为损坏，依然可以转移到读取其他完好的副本，并向 NameNode 汇报该文件 block 损坏，后续处理由 NameNode 通知 DataNode 删除损坏文件 block，并根据完好的副本来复制一份新的文件 block 副本。

## 4. Spark面试题
### 1. Spark为什么比MapReduce快？

1. spark是基于内存进行数据处理的，MapReduce是基于磁盘进行数据处理的。MapReduce的设计：中间结果保存在文件中，提高了可靠性，减少了内存占用。但是牺牲了性能。
   Spark的设计：数据在内存中进行交换，要快一些，但是内存这个东西，可靠性不如磁盘。所以性能方面比MapReduce要好。
   DAG计算模型在迭代计算上还是比MapReduce的效率更高。
2. Spark中**具有DAG有向无环图**，DAG有向无环图在此过程中**减少了shuffle以及落地磁盘的次数**
  Spark 计算比 MapReduce 快的根本原因在于 DAG 计算模型。一般而言，DAG 相比MapReduce 在大多数情况下可以减少 shuffle 次数。Spark 的 DAGScheduler 相当于一个改进版的 MapReduce，如果计算不涉及与其他节点进行数据交换，Spark 可以在内存中一次性完成这些操作，也就是中间结果无须落盘，减少了磁盘 IO 的操作。但是，如果计算过程中涉及数据交换，Spark 也是会把 shuffle 的数据写磁盘的！有一个误区，Spark 是基于内存的计算，所以快，这不是主要原因，要对数据做计算，必然得加载到内存，Hadoop 也是如此，只不过 Spark 支持将需要反复用到的数据给 Cache 到内存中，减少数据加载耗时，所以 Spark 跑机器学习算法比较在行（需要对数据进行反复迭代）。Spark 基于磁盘的计算也是比 Hadoop 快。刚刚提到了 Spark 的 DAGScheduler 是个改进版的 MapReduce，所以 Spark天生适合做批处理的任务。Hadoop 的 MapReduce 虽然不如 spark 性能好，但是 HDFS 仍然是业界的大数据存储标准。
3. spark是粗粒度资源申请，也就是当提交spark application的时候，application会将所有的资源申请完毕，如果申请不到资源就等待，如果申请到资源才执行application，task在执行的时候就不需要自己去申请资源，task执行快，当最后一个task执行完之后task才会被释放。

  优点是执行速度快，缺点是不能使集群得到充分的利用

  MapReduce是细粒度资源申请，当提交application的时候，task执行时，自己申请资源，自己释放资源，task执行完毕之后，资源立即会被释放，task执行的慢，application执行的相对比较慢。

  优点是集群资源得到充分利用，缺点是application执行的相对比较慢。

  Spark是基于内存的，而MapReduce是基于磁盘的迭代

### 2. Spark的RDD、DataFrame、DataSet、DataStream区别?

RDD叫做弹性分布数据集，是Spark中最基本的**数据处理模型**。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面元素可并行计算的集合。

![image-20220913123524315](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/image-20220913123524315.png)

在 Spark 中，DataFrame 是一种以 RDD 为基础的分布式数据集，类似于传统数据库中的二维表格。DataFrame 与 RDD 的主要区别在于，前者带有 schema 元信息，即 DataFrame所表示的二维表数据集的每一列都带有名称和类型。

DataSet是分布式数据集合。DataSet是Spark 1.6中添加的一个新抽象，是DataFrame的一个扩展。它提供了RDD的优势（强类型，使用强大的lambda函数的能力）以及Spark SQL优化执行引擎的优点。DataFrame=DataSet[Row]。



###  3. Spark的stage如何划分?在源码中是怎么判断属于Shuffle Map Stage或Result Stage的?



### 4. Spark的内存模型?

### 5. DAG为什么适合Spark?

### 6. Spark/RDD的容错

### 7. Spark的batchsize，怎么解决小文件合并问题?

### 8. RDD的缓存级别?

### 9. Spark广播变量的实现和原理?

### 10. 说下Spark checkpoint？

### 11. DAGScheduler是什么？

### 12. Spark的几种部署方式及好处

### 13. Spark的cache和persist的区别?它们是transformaiton算子还是action算子?

### 14. Spark Streaming的工作原理?

### 15. Spark Streaming的DStream和DStreamGraph的区别?

### 16. 介绍下Spark Streaming和Structed Streaming

### 17. DAG划分Spark源码实现?

### 18. Spark Streaming的双流join的过程，怎么做的?

### 19. Spark怎么保证数据不丢失

### 20. Spark Streaming怎么实现数据持久化保存?

### 21. Spark SQL读取文件，内存不够使用，如何处理?

### 22. Spark的exactly-once

### 23. Spark计算的灵活性？

## 5. Kafka面试题

### 1. 介绍下Kafka，Kafka的作用?Kafka的组件?适用场景?

Kafka是一个分布式的基于发布/订阅模式的消息队列(Message Queue)，主要应用于大数据实时处理领域。组件包括Producer、Consumer、Consumer Group、Broker、Topic、Partition、Replica、Leader、follower。

使用场景有：

- 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等。
- 消息系统：解耦和生产者和消费者、缓存消息等。
- 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
- 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
- 流式处理：比如spark streaming和 Flink

### 2. Kafka作为消息队列，它可解决什么样的问题?

1. 解耦

   允许独立扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束；

2. 可恢复性

   系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理；

3. 缓冲

   有助于控制和优化数据流过系统的速度，解决生产消息和消费消息的处理速度不一致的情况；

4. 灵活性和峰值处理能力

   在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃；

5. 异步通信

   用户有时不需要立即处理消息。消息队列提供了异步处理机制，允许用户把多个消息放入队列，但并不立即处理它。

### 3. Kafka的优缺点？

   优点

   - 支持多个生产者和消费者
   - 支持broker的横向拓展
   - 副本集机制，实现数据冗余，保证数据不丢失
   - 通过topic将数据进行分类
   - 通过分批发送压缩数据的方式，减少数据传输开销，提高吞吐量
   - 支持多种模式的消息
   - 基于磁盘实现数据的持久化
   - 高性能的处理信息，在大数据的情况下，可以保证亚秒级的消息延迟
   - 对资源的消耗比较小
   - 支持跨数据中心的数据复制
   - 支持镜像集群

   缺点

   - 由于是批量发送，数据并非真正的实时；
   - 对于mqtt协议不支持；
   - 仅支持统一分区内消息有序，无法实现全局消息有序；
   - 监控不完善，需要安装插件；
   - 依赖zookeeper进行元数据管理；
   - topic一般需要人工创建，部署和维护一般都比mq高。

### 4. Kafka相比于传统消息传递方式有什么优点？

**高性能**：单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作，Kafka性能远超过传统的ActiveMQ、RabbitMQ等，而且Kafka支持Batch操作；
**可扩展**：Kafka集群可以透明的扩展，增加新的服务器进集群；
**容错性**： Kafka每个Partition数据会复制到几台服务器，当某个Broker失效时，Zookeeper将通知生产者和消费者从而使用其他的Broker

### 5. Kafka怎么保证数据的可靠性？

可靠性 = 数据不丢失 + 数据一致性

数据不丢失：ack机制，数据一致性：LEO和ISR机制

### 6. Kafka如何保证全局有序?

```
全局使用一个生产者 
全局使用一个消费者（并严格到一个消费线程） 
全局使用一个分区（当然不同的表可以使用不同的分区或者topic实现隔离与扩展）
```

这样做效率极低

比如
在1个topic中，有3个partition，那么如何保证数据的消费？

比如可以以订单ID作为key,然后取Hash,那么订单ID相同的一定会分到同一分区.
同一分区的数据如果只有一个消费者单线程消费,那么一定也是有序的.
同一分区的数据如果有多个线程消费，就需要写N个queue，将具有相同key的数据都存储在同一个queue，然后对于N个线程，每个线程分别消费一个queue即可。

### 7. 生产者消费者模式与发布订阅模式有何异同?

生产者/消费者模式是一对一消费，生产者生产消息到队列中，消费中从队列中消费消息，消息被消费完以后从队列中删除，其他消费者无法消费。一个队列支持多个消费者进行消费，但对一个消息只有一个消费者可以消费。

发布/订阅模式是生产者将消息发布到topic中，同时有多个消费者消费该消息，和点对点模式不同，发布到topic的消息可被所有消费者消费。

### 8. Kafka中为什么同一个消费者组的消费者不能消费相同的分区？
消费者拉取消息需要提供offset, limit。
如果offset放在broker端，那么一定会产生额外的通信开销；
如果offset放在Consumer端，如果在一个组有多个消费者，就需要有一个协调者，集中式的管理，解决锁冲突，如果不解决冲突，那么势必会产生**重复消费**、无用的消费，从而导致资源浪费。
kafka已经实现分布式消费，多个消费组同时消费同一个分区就可以，处于权衡目的，没有再细化到消费组内再分布消费。

### 9. Kakfa中的offset

**Current offset**

- Current offset 保存在客户端中由客户端自己维护，它表示消费者希望收到下一条消息的序号，它仅仅在poll()方法中使用，例如：消费者第一次调用poll()方法收到了20条消息，那么 cuttent offset的值将被设置成20 下一次poll时，kafka就知道要从序号为21的消息开始读取，这样能保证消费者每次poll消息时，收到的消息不重复 

​    **Committed offset**

- Committed Offset保存在Broker上 (V0.9之后的版本)，它表示Consumer已经确认消费过的消息的序号。主要通过commitSync()来操作。举例:Consumer通过poll()方法收到20条消息后，此时Current Offset就是20，经过一系列的逻辑处理后，并没有调用commitSync()来提交Committed Offset，那么此时Committed Offset依旧是0。
- Committed Offset主要用于Consumer Rebalance(再平衡)。在Consumer Rebalance的过程中，一个Partition被分配给了一个Consumer，那么这个Consumer该从什么位置开始消费消息呢?答案就是Committed Offset。另外，如果一个Consumer消费了5条消息.(poll并且成功commitSync)之后宕机了，重新启动之后，它仍然能够从第6条消息开始消费，因为Committed Offset已经被Kafka记录为5。
- Committed Offset是为了每一个消费组进行记录的 不同的消费者组分别记录

Current offset 是针对消费者 poll过程为了保证每次poll都返回不重复的消息

Committed offset 是为了 Consumer Rebalance(再平衡) 的你过程，它能够保证同一个消费者组中新的消费者在正确的位置开始消费，避免重复消费。

### 10. Kafka支持什么语义？怎么实现ExactlyOnlyOnce?

**生产者-Broker：**

ack机制+ExactlyOnlyOnce

at-most-once ： ack = 0,1

at-least-once：ack = -1

**消费者-Broker**：
at-least-once
这种语义有可能会对数据重复处理
1: 设置enable.auto.commit为false，禁用自动提交offset
2: 消息处理完之后手动调用consumer.commitSync()提交offset

这种方式是在消费数据之后，手动调用函数consumer.commitSync()异步提交offset，有可能处理多次的场景是消费者的消息处理完并输出到结果库，但是offset还没提交，这个时候消费者挂掉了，再重启的时候会重新消费并处理消息，所以至少会处理一次

at-most-once
这种语义有可能会丢失数据
至多一次消费语义是kafka消费者的默认实现。配置这种消费者最简单的方式是
1: enable.auto.commit设置为true。
2: auto.commit.interval.ms设置为一个较低的时间范围。
由于上面的配置，此时kafka会有一个独立的线程负责按照指定间隔提交offset。

消费者的offset已经提交，但是消息还在处理中(还没有处理完)，这个时候程序挂了，导致数据没有被成 功处理，再重启的时候会从上次提交的offset处消费，导致上次没有被成功处理的消息就丢失了。

ExactlyOnlyOnce
这种语义可以保证数据只被消费处理一次。
1: 将enable.auto.commit设置为false，禁用自动提交offset
2: 使用consumer.seek(topicPartition，offset)来指定offset
3: 在处理消息的时候，要同时保存住每个消息的offset。

以原子事务的方式保存offset和处理的消息结 果，这个时候相当于自己保存offset信息了，把offset和具体的数据绑定到一块，数据真正处理成功的时 候才会保存offset信息

这样就可以保证数据仅被处理一次了。

### 11. Kafka创建Topic时如何将分区放置到不同的Broker中

- 副本因子不能大于 Broker 的个数；
- 第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；
- 其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；
- 剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的

### 12. 谈一谈 Kafka 的再均衡(rebalance)

在Kafka中，当有新消费者加入或者订阅的topic数发生变化时，会触发Rebalance(再均衡：在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者)机制，Rebalance顾名思义就是重新均衡消费者消费。Rebalance的过程如下：

①所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。

②leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。所以对于Rebalance来说，Coordinator起着至关重要的作用。

### 13. Kafka在搭建的时候要配置什么参数？

1、broker.id：broker标识符，默认是0。

2、port：端口，如果使用配置样本来启动Kafka，会默认监听9092端口。

3、zookeeper.connect：用于保存broker元数据的ZooKeeper地址。该配置参数是用逗号分隔的一组hostname:port/path列表，每一部分含义如下：

（1）hostname是ZooKeeper服务器的机器名或IP地址；

（2）port是Zookeeper的客户端连接端口；

（3）/path是可选的Zookeeper路径，作为Kafka集群的chroot环境。如果不指定，默认使用根路径。

4、log.dirs：存放日志片段的目录。

5、num.recovery.threads.per.data.dir：线程池个数。

6、auto.create.topics.enable：是否自动创建主题。

### 14. SparkStreaming对接kafka的两种方式

1. ### receiver方式

	1、receiver不停地从kafkaq拉取数据，n秒钟（程序设置的）拉取产生一批数据
	2、这种方式偏移量zookeeper帮我们管理，灵活性差

这种方式有缺点：
    receiver从Kafka中获取的数据都存储在Spark Executor的内存中，某个时间段内拉去的数据可能会大于某台机器executor分配的内存数量，部分数据会溢出丢失。
    针对这一问题，1.2版本之后提供记log方式（Streaming的预写日志机制）(Write Ahead Log，WAL)。该机制会将从kafka中读取的数据先保存到hdfs或者S3上，然后再去消费数据，WAL是为了防止数据的丢失，可以对数据进行恢复。所以，即使底层节点出现了失败，也可以使用预写日志中的数据进行恢复。
使用时的注意事项：
    1）Kafka中topic的partition与Spark中RDD的partition是没有关系的，因此，在KafkaUtils.createStream()中，提高partition的数量，只会增加Receiver的数量，也就是读取Kafka中topic partition的线程数量，不会增加Spark处理数据的并行度。
    2）可以创建多个Kafka输入DStream，使用不同的consumer group和topic，来通过多个receiver并行接收数据。
    3）如果基于容错的文件系统，比如HDFS，启用了预写日志机制，接收到的数据都会被复制一份到预写日志中。因此，在KafkaUtils.createStream()中，设置的持久化级别是StorageLevel.MEMORY_AND_DISK_SER。

2. direct方式

这种方式会周期性地查询Kafka，获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。这种方式的偏移量可以由我们开发人员管理，这样的话，它的灵活性很好，并且可以保证数据的安全性，而且不用担心数据量过大，因为他有预处理机制，进行提前处理，然后批次提交任务。

这种方式有如下的优点：
1)简化并行读取
如果要读取多个partition，不需要创建多个输入DStream，然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在Kafka partition和RDD partition之间，有一个一对一的映射关系。

2）高性能
如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有。

而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。

3）一次且仅一次的事务机制
基于receiver的方式，是使用Kafka的高阶API来在ZooKeeper中保存消费过的offset的。这是消费Kafka数据的传统方式。这种方式配合着WAL机制可以保证数据零丢失的高可靠性，但是却无法保证数据被处理一次且仅一次，可能会处理两次。
基于direct的方式，使用kafka的简单api，Spark Streaming自己就负责追踪消费的offset，并保存在checkpoint中。Spark自己一定是同步的，因此可以保证数据是消费一次且仅消费一次。



### 15. Zookeeper在Kafka中的应用

1）Controller选举

Kafka集群中会有一个Broker会被选举为Controller，对zookeeper进行监听，负责管理**broker的上下线**，所有**topic的分区副本分配**和**leader选举工作**。	

2）配置管理

Topic的配置之所以可以动态更新就是基于zookeeper做了一个动态全局配置管理。

3）负载均衡

基于zookeeper的消费者，实现了该特性，动态感知分区变动，将负载使用到既定分配策略分不到的消费者上。

4）分布式通知

如分区增加、Broker下线、topic变动等；

5）集群管理和master选举

可以通过命令行，对kafka集群上的topic partition分布，进行迁移管理，也可以对partition leader选举进行干预。

### 16. Kafka如何防止脑裂

kafka中只有一个控制器controller 负责分区的leader选举，同步broker的新增或删除消息，但有时由于网络问题，可能同时有两个broker认为自己是controller，这时候其他的broker就会发生脑裂，不知道该听从谁的。

每当新的controller产生的时候就会在zk中生成一个全新的、数值更大的controller epoch的标识，并同步给其他的broker进行保存，这样当第二个controller发送指令时，其他的broker就会自动忽略。


## 6. 在1G大小的文件中，找出高频top100的单词

问：假如有一个1G大小的文件，文件里每一行是一个词，每个词的大小不超过16byte，要求返回出现频率最高的100个词。内存大小限制10M。

答：由于内存限制，我们无法将大文件的所有词一次性读到内存中，因此可以采用分治的策略，保证每个文件的大小小于10M，进而直接将单个小文件读到内存中进行处理。

第一步，遍历大文件，对遍历到的每个词x，执行hash(x)%500，将结果为i的词存放到文件f(i)中，遍历结束后可以得到500个小文件；之所以使用500个小文件，是因为原文件大小为1G，1G/500=2M，每个小文件的大小为2M左右，基本不会超过内存大小10M的限制。

第二步，接着统计每个小文件中出现频数最高的100个词，可以使用HashMap来实现，其中key为词，value为词频，对于遍历到的词，如果在map中存在，则执行map.put(x,map.get(x)+1)，将该词出现的次数+1。

第三步，在第二步中找出了每个文件出现频率最高的100个词之后，通过维护一个小顶堆来找出所有小文件中出现频率最高的100个词。具体方法是：遍历第一个文件，把第一个文件中出现频率最高的100个词构建成一个小顶堆，如果第一个文件中的词的个数小于100，则可以继续遍历第二个文件，知道构建好有100个结点的小顶堆为止。继续遍历其他小文件，如果遍历到的词的出现次数大于堆顶上词的出现次数，可以用新遍历到的词替换堆顶的词，然后重新调整这个堆为小顶堆。

总结一下，采用分治思想，进行哈希取余，使用HashMap统计每个小文件单词出现的次数；维护一个小顶堆，遍历步骤2中的小文件，找出出现频率top100的单词。

# 数据结构和算法

## 1. 排序算法的比较

 ![在这里插入图片描述](https://typora-1308702321.cos.ap-guangzhou.myqcloud.com/20210225144127497.png)
